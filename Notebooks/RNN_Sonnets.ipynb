{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Sonnets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z06BC6GkvUMi"
      },
      "source": [
        "## RNN LSTM Writing Sonnets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPy1RfsJiWE1",
        "outputId": "373f02bc-331c-4600-f11d-4a88859a3aa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_dir = '/content/drive/My Drive/'"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsV_6_bKie3H"
      },
      "source": [
        "text = (open(drive_dir + 'sonnets.txt').read())\n",
        "text=text.lower()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w894bKT0vZsV"
      },
      "source": [
        "Now we need to make a way to transer from characters to numbers and numbers to characters so two dictionarys are made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoqES3QDig_2"
      },
      "source": [
        "characters = sorted(list(set(text)))\n",
        "n_to_char = {n:char for n, char in enumerate(characters)}\n",
        "char_to_n = {char:n for n, char in enumerate(characters)}"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c93YUgxwvhUP"
      },
      "source": [
        "Now we are going to take a sequence of 100 of the characters and save the label of the next character. This essentially makes our data for x and y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfm8SudgijRY"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "length = len(text)\n",
        "seq_length = 100\n",
        "for i in range(length-seq_length):\n",
        "     sequence = text[i:i + seq_length]\n",
        "     label =text[i + seq_length]\n",
        "     X.append([char_to_n[char] for char in sequence])\n",
        "     Y.append(char_to_n[label])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns0_LsuUvvo3"
      },
      "source": [
        "Simple preprocessing for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09N0YxuIilmh"
      },
      "source": [
        "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
        "X_modified = X_modified / float(len(characters))\n",
        "Y_modified = np_utils.to_categorical(Y)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lggENs1vyKS"
      },
      "source": [
        "LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y79nlXZimFw"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(400, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(400))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "231rRfG-n6vX",
        "outputId": "d2a64752-39ef-40cb-d1b8-4f5e02076415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_modified, Y_modified, epochs=10, batch_size=100)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "979/979 [==============================] - 57s 59ms/step - loss: 2.5029\n",
            "Epoch 2/10\n",
            "979/979 [==============================] - 59s 61ms/step - loss: 2.3486\n",
            "Epoch 3/10\n",
            "979/979 [==============================] - 59s 61ms/step - loss: 2.2346\n",
            "Epoch 4/10\n",
            "979/979 [==============================] - 59s 61ms/step - loss: 2.1409\n",
            "Epoch 5/10\n",
            "979/979 [==============================] - 59s 61ms/step - loss: 2.0581\n",
            "Epoch 6/10\n",
            "979/979 [==============================] - 59s 61ms/step - loss: 1.9867\n",
            "Epoch 7/10\n",
            "979/979 [==============================] - 59s 61ms/step - loss: 1.9187\n",
            "Epoch 8/10\n",
            "979/979 [==============================] - 59s 61ms/step - loss: 1.8555\n",
            "Epoch 9/10\n",
            "979/979 [==============================] - 59s 61ms/step - loss: 1.8016\n",
            "Epoch 10/10\n",
            "979/979 [==============================] - 59s 61ms/step - loss: 1.7416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTlJaJB3x7au"
      },
      "source": [
        "model.save_weights(drive_dir + '/saved_models/text_generator_400_0.2_400_0.2_baseline.h5')"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfGtSBpGxu31"
      },
      "source": [
        "model.load_weights(drive_dir + '/saved_models/text_generator_400_0.2_400_0.2_baseline.h5')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-2JSeB0v1GE"
      },
      "source": [
        "Now we can print the predictions. Below a starter string is given and then the model makes predictions using softmax and the np.argmax finds the position of the highest predictions. It then appends that corresponding letter to the string from the beginning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QkCYcwBion2",
        "outputId": "b9ffc5b2-6a59-4d2d-b8c5-6481a63f410a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "string_mapped = X[99]\n",
        "full_string = [n_to_char[value] for value in string_mapped]\n",
        "# generating characters\n",
        "for i in range(400):\n",
        "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
        "    x = x / float(len(characters))\n",
        "\n",
        "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
        "    seq = [n_to_char[value] for value in string_mapped]\n",
        "    full_string.append(n_to_char[pred_index])\n",
        "\n",
        "    string_mapped.append(pred_index)\n",
        "    string_mapped = string_mapped[1:len(string_mapped)]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 100, 1) for input Tensor(\"lstm_4_input:0\", shape=(None, 100, 1), dtype=float32), but it was called on an input with incompatible shape (None, 101, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gZHaHY7oQ5s",
        "outputId": "7dde79f6-da18-4649-ccf4-bb2cb61bdeb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "txt=\"\"\n",
        "for char in full_string:\n",
        "    txt = txt+char\n",
        "print(txt)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s the riper should by time decease,\n",
            " his tender heir might bear his memory:\n",
            " but thou, contracted to the world she steet,\n",
            " and there brreld with thee that think the steet,\n",
            " and there brreld with thee that think the steet,\n",
            " and there brreld with thee that think the steet,\n",
            " and there brreld with thee that think the steet,\n",
            " and there brreld with thee that think the steet,\n",
            " and there brreld with thee that think the steet,\n",
            " and there brreld with thee that think the steet,\n",
            " and there brreld with thee t\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}