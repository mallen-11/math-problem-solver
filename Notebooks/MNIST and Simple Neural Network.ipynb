{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will identify how to load the MNIST data set properly and run an extremely simple version of a nueral network that classifies numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the shape and what the first picture looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff38e0ed710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the first picture looks like a 5 and in the data set it is identified as a 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to divde the value associated with each pixel by 255 since that is the total number of pixels. We will do this so each value is between 0 and 1. 0 represents a white pixel and 1 represents a black pixel. Anything in between is how we will end up identifying our numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now we have loaded the MNIST data from TensorFlow. Also we have seen what the first value of the training set is. Keep in mind there is also a test set of about 10,000 values to use later on as validation for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a few examples of very simple neural networks that actually perform quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model is made with 10 hidden layers. 10 because of the digits 0-9. Also 'softmax' is simple what outputs probabilities. This will make the behind the scenes stuff easier to understand and help the model learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we must compile our model. We will need a loss function and an optimizer. There are many different types but these are what were selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.4609 - accuracy: 0.8811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff38e130450>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this simple model with no epochs tested at 88% accuracy which isn't too bad. Next we are going to add some epochs. This basically does this same process over and over to increase the computers accuracy. Be careful though as too many epochs can lead to overtraining where the model memorizes the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.3033 - accuracy: 0.9151\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 730us/step - loss: 0.2837 - accuracy: 0.9204\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 735us/step - loss: 0.2729 - accuracy: 0.9237\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 746us/step - loss: 0.2664 - accuracy: 0.9251\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 802us/step - loss: 0.2620 - accuracy: 0.9273\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 740us/step - loss: 0.2581 - accuracy: 0.9283\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 751us/step - loss: 0.2554 - accuracy: 0.9294\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 733us/step - loss: 0.2533 - accuracy: 0.9297\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 740us/step - loss: 0.2508 - accuracy: 0.9306\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 810us/step - loss: 0.2491 - accuracy: 0.9312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff35db5dc10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! That model now predicted images at 93% which is a large improvment. Lastly, we will add a validation training set so that we can make sure the model isn't overtraining and is instead actually learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.2486 - accuracy: 0.9305 - val_loss: 0.2489 - val_accuracy: 0.9312\n",
      "Epoch 2/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2457 - accuracy: 0.9313 - val_loss: 0.2489 - val_accuracy: 0.9329\n",
      "Epoch 3/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2436 - accuracy: 0.9320 - val_loss: 0.2522 - val_accuracy: 0.9321\n",
      "Epoch 4/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2424 - accuracy: 0.9322 - val_loss: 0.2559 - val_accuracy: 0.9306\n",
      "Epoch 5/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2412 - accuracy: 0.9323 - val_loss: 0.2566 - val_accuracy: 0.9302\n",
      "Epoch 6/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2397 - accuracy: 0.9339 - val_loss: 0.2604 - val_accuracy: 0.9293\n",
      "Epoch 7/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2384 - accuracy: 0.9338 - val_loss: 0.2610 - val_accuracy: 0.9287\n",
      "Epoch 8/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2368 - accuracy: 0.9335 - val_loss: 0.2643 - val_accuracy: 0.9276\n",
      "Epoch 9/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2364 - accuracy: 0.9348 - val_loss: 0.2657 - val_accuracy: 0.9294\n",
      "Epoch 10/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2354 - accuracy: 0.9349 - val_loss: 0.2678 - val_accuracy: 0.9273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff38e1da490>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still performing well. Next we are going to add a few layers to our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Dense(100), \n",
    "                    Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.3824 - accuracy: 0.8915 - val_loss: 0.3220 - val_accuracy: 0.9054\n",
      "Epoch 2/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.3034 - accuracy: 0.9155 - val_loss: 0.3156 - val_accuracy: 0.9087\n",
      "Epoch 3/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2872 - accuracy: 0.9199 - val_loss: 0.3183 - val_accuracy: 0.9111\n",
      "Epoch 4/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2801 - accuracy: 0.9211 - val_loss: 0.2953 - val_accuracy: 0.9191\n",
      "Epoch 5/10\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.2747 - accuracy: 0.9228 - val_loss: 0.3075 - val_accuracy: 0.9141\n",
      "Epoch 6/10\n",
      "1313/1313 [==============================] - 2s 2ms/step - loss: 0.2718 - accuracy: 0.9230 - val_loss: 0.3094 - val_accuracy: 0.9164\n",
      "Epoch 7/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2661 - accuracy: 0.9245 - val_loss: 0.3134 - val_accuracy: 0.9135\n",
      "Epoch 8/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2653 - accuracy: 0.9249 - val_loss: 0.2945 - val_accuracy: 0.9193\n",
      "Epoch 9/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2623 - accuracy: 0.9261 - val_loss: 0.2959 - val_accuracy: 0.9182\n",
      "Epoch 10/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2590 - accuracy: 0.9266 - val_loss: 0.3090 - val_accuracy: 0.9131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff32d86b710>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this didn't actually help the training much but with the right mix of layers you can help your model learn a lot. One more nueral network just for practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = Sequential([Dense(10),\n",
    "                         Dense(40),\n",
    "                         Dense(60),\n",
    "                         Dense(40),\n",
    "                   Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.4427 - accuracy: 0.8700 - val_loss: 0.3451 - val_accuracy: 0.9013\n",
      "Epoch 2/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.3252 - accuracy: 0.9063 - val_loss: 0.3155 - val_accuracy: 0.9105\n",
      "Epoch 3/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.3045 - accuracy: 0.9142 - val_loss: 0.3107 - val_accuracy: 0.9139\n",
      "Epoch 4/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2980 - accuracy: 0.9167 - val_loss: 0.3088 - val_accuracy: 0.9135\n",
      "Epoch 5/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2909 - accuracy: 0.9173 - val_loss: 0.3128 - val_accuracy: 0.9133\n",
      "Epoch 6/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2853 - accuracy: 0.9195 - val_loss: 0.3173 - val_accuracy: 0.9154\n",
      "Epoch 7/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2804 - accuracy: 0.9206 - val_loss: 0.3063 - val_accuracy: 0.9121\n",
      "Epoch 8/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2776 - accuracy: 0.9216 - val_loss: 0.3101 - val_accuracy: 0.9158\n",
      "Epoch 9/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2748 - accuracy: 0.9207 - val_loss: 0.3170 - val_accuracy: 0.9097\n",
      "Epoch 10/10\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2722 - accuracy: 0.9224 - val_loss: 0.3139 - val_accuracy: 0.9142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff31a7237d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(X_train, y_train, epochs=10, validation_split=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
