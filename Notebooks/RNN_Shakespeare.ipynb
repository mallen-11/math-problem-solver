{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Shakespeare.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfLQ5c0xyn5W"
      },
      "source": [
        "# Poem RNN\n",
        "\n",
        "Generating a poem based on Shakespeare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-X4XAA-yn5X"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Embedding\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import sys\n",
        "\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QRFTMph7Fxq",
        "outputId": "c2752f6b-68a9-4433-9c66-e5aeb4a4dc56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_dir = '/content/drive/My Drive/'"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRY5gff3yn5e"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udhkCIm-yn5g"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w894bKT0vZsV"
      },
      "source": [
        "Now we need to make a way to transer from characters to numbers and numbers to characters so two dictionarys are made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoqES3QDig_2"
      },
      "source": [
        "characters = sorted(list(set(text)))\n",
        "n_to_char = {n:char for n, char in enumerate(characters)}\n",
        "char_to_n = {char:n for n, char in enumerate(characters)}"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c93YUgxwvhUP"
      },
      "source": [
        "Now we are going to take a sequence of 100 of the characters and save the label of the next character. This essentially makes our data for x and y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfm8SudgijRY"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "length = len(text)\n",
        "seq_length = 100\n",
        "for i in range(length-seq_length):\n",
        "     sequence = text[i:i + seq_length]\n",
        "     label =text[i + seq_length]\n",
        "     X.append([char_to_n[char] for char in sequence])\n",
        "     Y.append(char_to_n[label])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns0_LsuUvvo3"
      },
      "source": [
        "Simple preprocessing for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09N0YxuIilmh"
      },
      "source": [
        "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
        "X_modified = X_modified / float(len(characters))\n",
        "Y_modified = np_utils.to_categorical(Y)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lggENs1vyKS"
      },
      "source": [
        "LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y79nlXZimFw"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(400, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(400))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "231rRfG-n6vX",
        "outputId": "ca6aca96-6256-487a-d8c8-84e77f8710eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_modified, Y_modified, epochs=1, batch_size=100)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11153/11153 [==============================] - 681s 61ms/step - loss: 2.3166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8d61663fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTlJaJB3x7au"
      },
      "source": [
        "model.save_weights(drive_dir + '/saved_models/text_generator_400_0.2_400_0.2_shakespeare.h5')"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfGtSBpGxu31"
      },
      "source": [
        "model.load_weights(drive_dir + '/saved_models/text_generator_400_0.2_400_0.2_shakespeare.h5')"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-2JSeB0v1GE"
      },
      "source": [
        "Now we can print the predictions. Below a starter string is given and then the model makes predictions using softmax and the np.argmax finds the position of the highest predictions. It then appends that corresponding letter to the string from the beginning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QkCYcwBion2"
      },
      "source": [
        "string_mapped = X[199]\n",
        "full_string = [n_to_char[value] for value in string_mapped]\n",
        "# generating characters\n",
        "for i in range(400):\n",
        "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
        "    x = x / float(len(characters))\n",
        "\n",
        "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
        "    seq = [n_to_char[value] for value in string_mapped]\n",
        "    full_string.append(n_to_char[pred_index])\n",
        "\n",
        "    string_mapped.append(pred_index)\n",
        "    string_mapped = string_mapped[1:len(string_mapped)]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gZHaHY7oQ5s",
        "outputId": "d01ca508-98dd-43d0-a8fd-b88a5ff74ca2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "txt=\"\"\n",
        "for char in full_string:\n",
        "    txt = txt+char\n",
        "print(txt)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "u know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let uhe searee of the world the will the searent\n",
            "That the world the will the will the will the searen of the searent\n",
            "That the world the will the will the baute the will the searent\n",
            "That the world the will the will the baute the will the searent That she would the will the will the baute the will the searen of the searent That she would the will the baute the will the baute the searent That she would th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmd-icj22ugE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}