{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xUzM901Sjpe"
   },
   "source": [
    "# Image Captioning with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23950,
     "status": "ok",
     "timestamp": 1605553608791,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "rMgFop76Sjpf",
    "outputId": "b2cf6200-462f-466c-c514-b99318169097"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import image\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqP6UkWTSjpj"
   },
   "source": [
    "Loading the Data. The data consist of pictures and labels of linear functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1605553609779,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "08AiJm9zSjpk"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def load_images_from_folder(folder, n_imgs=-1):\n",
    "    images = []\n",
    "    image_nums = []\n",
    "    for filename in os.listdir(folder)[:n_imgs]:\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            image_nums.append(filename.strip('.png'))\n",
    "    return images, image_nums\n",
    "\n",
    "folder=\"../../../Math Equations/linear_fcns/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 45955,
     "status": "ok",
     "timestamp": 1605554061902,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "vBBKDvA8Sjpm"
   },
   "outputs": [],
   "source": [
    "images, fnames = load_images_from_folder(folder,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WYkOrKFFSjpp"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../../../Math Equations/linear_fcns/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JoZjytqMWTiR"
   },
   "outputs": [],
   "source": [
    "labels['img_number'] = labels['filename'].apply(lambda x: x.split('/')[-1].strip('.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1605395495815,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "vC3wCKPxWQaC",
    "outputId": "902efffe-60ca-411b-f507-a329adf0f01a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latex</th>\n",
       "      <th>filename</th>\n",
       "      <th>img_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0a+1=2</td>\n",
       "      <td>linear_fcns/images/0.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0b+1=2</td>\n",
       "      <td>linear_fcns/images/1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0c+1=2</td>\n",
       "      <td>linear_fcns/images/2.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0d+1=2</td>\n",
       "      <td>linear_fcns/images/3.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e+1=2</td>\n",
       "      <td>linear_fcns/images/4.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latex                  filename img_number\n",
       "0  0a+1=2  linear_fcns/images/0.png          0\n",
       "1  0b+1=2  linear_fcns/images/1.png          1\n",
       "2  0c+1=2  linear_fcns/images/2.png          2\n",
       "3  0d+1=2  linear_fcns/images/3.png          3\n",
       "4  0e+1=2  linear_fcns/images/4.png          4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DC-tLPESWAy5"
   },
   "outputs": [],
   "source": [
    "label_array = labels[labels['img_number'].isin(fnames)]['latex'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXR3M4QBSjpv"
   },
   "source": [
    "For the labels we need to add start and end tokens so the model can recognize what to write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NEzxzBX8Sjpv"
   },
   "outputs": [],
   "source": [
    "label_array = [f'\\t{la}\\n' for la in label_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHztSmQ_Sjpy"
   },
   "source": [
    "Let's reshape the images so we can plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1605395503599,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "9XdF3xaGSjpy",
    "outputId": "9b633ce9-2750-4b1c-e926-9f2b75a9d58f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 72, 360, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_for_split = images\n",
    "images = np.array(images)\n",
    "images = 255 - images\n",
    "# images = tf.image.rgb_to_grayscale(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb0da1b8710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQYvxF90Sjp3"
   },
   "source": [
    "Now we can process them and prepare them for inceptionv3 which is transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train, img_test, img_train_name, img_test_name = train_test_split(images, label_array, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mini = tf.image.resize_with_pad(img_train, 299, 299)\n",
    "img_test= tf.image.resize_with_pad(img_test, 299, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pE87-f9ESjp4"
   },
   "outputs": [],
   "source": [
    "img_mini = tf.keras.applications.inception_v3.preprocess_input(img_mini)\n",
    "img_test = tf.keras.applications.inception_v3.preprocess_input(img_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-8n1FtqSjp8"
   },
   "source": [
    "Now we can load the features of the inceptionv3 model as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mini0 = (img_mini[0] + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1605395508912,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "8uSNNnvdSjp6",
    "outputId": "c123a164-46bf-4b86-9368-f105029f9f0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb0da24e910>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.squeeze(img_mini0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hgB8p8KZSjp8"
   },
   "outputs": [],
   "source": [
    "image_model = tf.keras.applications.InceptionV3(include_top=False,\n",
    "                                                weights='imagenet')\n",
    "new_input = image_model.input\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "\n",
    "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "llWCIcu3Sjp_"
   },
   "outputs": [],
   "source": [
    "# Feel free to change batch_size according to your system configuration\n",
    "image_dataset = tf.data.Dataset.from_tensor_slices((img_mini, img_train_name)).batch(500)#(img_mini, label_array)).batch(1)\n",
    "c = 1\n",
    "\n",
    "for img, label in image_dataset:\n",
    "    batch_features = image_features_extract_model(img)\n",
    "    batch_features = tf.reshape(batch_features,\n",
    "                              (batch_features.shape[0], -1, batch_features.shape[3]))\n",
    "  \n",
    "    p = f'../Batch Features Train/batch_features{c}'\n",
    "    c = c+1 \n",
    "     #path_of_feature = p.numpy().decode(\"utf-8\")\n",
    "    np.save(p, batch_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iKq5_-oTP22q"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Batch Features Train/batch_features15.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f04f2bd55223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Batch Features Train/batch_features1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../Batch Features Train/batch_features{i}.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimg_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Batch Features Train/batch_features15.npy'"
     ]
    }
   ],
   "source": [
    "img_load = np.load('../Batch Features Train/batch_features1.npy')\n",
    "for i in range(2,21):\n",
    "    img_add = np.load(f'../Batch Features Train/batch_features{i}.npy')\n",
    "    img_load = np.concatenate((img_load, img_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1605396800358,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "js8_OsgYQLM3",
    "outputId": "cda0393f-c083-4bfd-96f5-e5e67e122071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 64, 2048)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_load.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dywlI7LUSjqC"
   },
   "source": [
    "### Tokenizing the labels\n",
    "\n",
    "Now we can pad the labels to make sure they are all the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xPgRuUgBbnPJ"
   },
   "outputs": [],
   "source": [
    "# Find the maximum length of any caption in our dataset\n",
    "def calc_max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Gipm5btLaNTb"
   },
   "outputs": [],
   "source": [
    "# Choose the top 5000 words from the vocabulary\n",
    "top_k = 41\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n",
    "                                                  oov_token=\"<unk>\",\n",
    "                                                  filters=' ',\n",
    "                                                  char_level=True)\n",
    "tokenizer.fit_on_texts(img_train_name)#label_array)\n",
    "train_seqs = tokenizer.texts_to_sequences(img_train_name)\n",
    "\n",
    "# Padding\n",
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "\n",
    "# Create the tokenized vectors\n",
    "train_seqs = tokenizer.texts_to_sequences(img_train_name)\n",
    "\n",
    "# Pad each vector to the max_length of the captions\n",
    "# If you do not provide a max_length value, pad_sequences calculates it automatically\n",
    "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')\n",
    "\n",
    "# Calculates the max_length, which is used to store the attention weights\n",
    "max_length = calc_max_length(train_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1605396804461,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "YfFg62gAcaL9",
    "outputId": "2f57f655-d469-4ca3-c192-68bd3b2e5087"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_words': 41,\n",
       " 'filters': ' ',\n",
       " 'lower': True,\n",
       " 'split': ' ',\n",
       " 'char_level': True,\n",
       " 'oov_token': '<unk>',\n",
       " 'document_count': 7000,\n",
       " 'word_counts': '{\"\\\\t\": 7000, \"7\": 2123, \"j\": 287, \"+\": 7000, \"1\": 2057, \"=\": 7000, \"8\": 2164, \"\\\\n\": 7000, \"4\": 2111, \"m\": 279, \"5\": 2114, \"o\": 260, \"6\": 2188, \"t\": 275, \"h\": 263, \"3\": 2051, \"w\": 250, \"p\": 286, \"c\": 256, \"2\": 1995, \"0\": 2033, \"9\": 2164, \"u\": 258, \"e\": 249, \"k\": 272, \"l\": 281, \"g\": 271, \"a\": 266, \"y\": 263, \"d\": 266, \"f\": 270, \"n\": 279, \"r\": 293, \"q\": 275, \"z\": 271, \"s\": 264, \"v\": 262, \"i\": 286, \"x\": 253, \"b\": 265}',\n",
       " 'word_docs': '{\"\\\\t\": 7000, \"\\\\n\": 7000, \"1\": 2057, \"=\": 7000, \"7\": 2123, \"j\": 287, \"8\": 2164, \"+\": 7000, \"4\": 2111, \"m\": 279, \"5\": 2114, \"o\": 260, \"6\": 2188, \"t\": 275, \"3\": 2051, \"h\": 263, \"w\": 250, \"p\": 286, \"2\": 1995, \"c\": 256, \"0\": 2033, \"9\": 2164, \"u\": 258, \"e\": 249, \"k\": 272, \"l\": 281, \"g\": 271, \"a\": 266, \"y\": 263, \"d\": 266, \"f\": 270, \"n\": 279, \"r\": 293, \"q\": 275, \"z\": 271, \"s\": 264, \"v\": 262, \"i\": 286, \"x\": 253, \"b\": 265}',\n",
       " 'index_docs': '{\"2\": 7000, \"5\": 7000, \"12\": 2057, \"4\": 7000, \"9\": 2123, \"17\": 287, \"7\": 2164, \"3\": 7000, \"11\": 2111, \"21\": 279, \"10\": 2114, \"36\": 260, \"6\": 2188, \"23\": 275, \"13\": 2051, \"33\": 263, \"40\": 250, \"18\": 286, \"15\": 1995, \"38\": 256, \"14\": 2033, \"8\": 2164, \"37\": 258, \"41\": 249, \"25\": 272, \"20\": 281, \"26\": 271, \"29\": 266, \"34\": 263, \"30\": 266, \"28\": 270, \"22\": 279, \"16\": 293, \"24\": 275, \"27\": 271, \"32\": 264, \"35\": 262, \"19\": 286, \"39\": 253, \"31\": 265}',\n",
       " 'index_word': '{\"1\": \"<unk>\", \"2\": \"\\\\t\", \"3\": \"+\", \"4\": \"=\", \"5\": \"\\\\n\", \"6\": \"6\", \"7\": \"8\", \"8\": \"9\", \"9\": \"7\", \"10\": \"5\", \"11\": \"4\", \"12\": \"1\", \"13\": \"3\", \"14\": \"0\", \"15\": \"2\", \"16\": \"r\", \"17\": \"j\", \"18\": \"p\", \"19\": \"i\", \"20\": \"l\", \"21\": \"m\", \"22\": \"n\", \"23\": \"t\", \"24\": \"q\", \"25\": \"k\", \"26\": \"g\", \"27\": \"z\", \"28\": \"f\", \"29\": \"a\", \"30\": \"d\", \"31\": \"b\", \"32\": \"s\", \"33\": \"h\", \"34\": \"y\", \"35\": \"v\", \"36\": \"o\", \"37\": \"u\", \"38\": \"c\", \"39\": \"x\", \"40\": \"w\", \"41\": \"e\", \"0\": \"<pad>\"}',\n",
       " 'word_index': '{\"<unk>\": 1, \"\\\\t\": 2, \"+\": 3, \"=\": 4, \"\\\\n\": 5, \"6\": 6, \"8\": 7, \"9\": 8, \"7\": 9, \"5\": 10, \"4\": 11, \"1\": 12, \"3\": 13, \"0\": 14, \"2\": 15, \"r\": 16, \"j\": 17, \"p\": 18, \"i\": 19, \"l\": 20, \"m\": 21, \"n\": 22, \"t\": 23, \"q\": 24, \"k\": 25, \"g\": 26, \"z\": 27, \"f\": 28, \"a\": 29, \"d\": 30, \"b\": 31, \"s\": 32, \"h\": 33, \"y\": 34, \"v\": 35, \"o\": 36, \"u\": 37, \"c\": 38, \"x\": 39, \"w\": 40, \"e\": 41, \"<pad>\": 0}'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1605396805750,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "GhqB3K30dMEo",
    "outputId": "aa4eee8d-77a9-4033-c9e3-2fea59b698fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1605396806687,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "QKIAGkIIb5ty",
    "outputId": "ddfd8187-4314-40ca-f60f-abd639d21457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0i+1=2\n",
      " -> [2, 9, 17, 3, 12, 4, 7, 5]\n"
     ]
    }
   ],
   "source": [
    "print(f'{label_array[0]} -> {train_seqs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1605396807076,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "wWBs6Njidhy4",
    "outputId": "c72990bc-4ddb-4444-ecfe-89622e4d5e17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 9, 17, 3, 12, 4, 7, 5]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "char_to_int_map = tokenizer.get_config()['word_index']\n",
    "char_to_int_map = json.loads(char_to_int_map)\n",
    "[char_to_int_map[c] for c in img_train_name[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dmak8HTlSjqT"
   },
   "outputs": [],
   "source": [
    "# Feel free to change these parameters according to your system's configuration\n",
    "embedding_dim = 45\n",
    "units = 32\n",
    "vocab_size = top_k + 1\n",
    "num_steps = len(img_train) // 1\n",
    "# Shape of the vector extracted from InceptionV3 is (64, 2048)\n",
    "# These two variables represent that vector shape\n",
    "features_shape = 2048\n",
    "attention_features_shape = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8xkSSS7Sjqb"
   },
   "source": [
    "## Model\n",
    "\n",
    "Below we are defining the attention, the encoder and the decoder. The encoder is just a fully connected layer from the features already extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "f7L_cEJzSjqc"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n",
    "\n",
    "        # hidden shape == (batch_size, hidden_size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        # attention_hidden_layer shape == (batch_size, 64, units)\n",
    "        attention_hidden_layer = (tf.nn.tanh(self.W1(features) +\n",
    "                                             self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # score shape == (batch_size, 64, 1)\n",
    "        # This gives you an unnormalized score for each image feature.\n",
    "        score = self.V(attention_hidden_layer)\n",
    "\n",
    "        # attention_weights shape == (batch_size, 64, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Eij3DZsYSjqe"
   },
   "outputs": [],
   "source": [
    "class CNN_Encoder(tf.keras.Model):\n",
    "    # Since you have already extracted the features and dumped it using pickle\n",
    "    # This encoder passes those features through a Fully connected layer\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        # shape after fc == (batch_size, 64, embedding_dim)\n",
    "        self.fc = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc(x)\n",
    "        #print(f'This is x: {x}')\n",
    "        x = tf.nn.relu(x)\n",
    "        #print(f'This is x: {x}')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "dLl75ZtPSjqh"
   },
   "outputs": [],
   "source": [
    "class RNN_Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units, vocab_size):\n",
    "        super(RNN_Decoder, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc1 = tf.keras.layers.Dense(self.units)\n",
    "        self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        #self.attention = BahdanauAttention(self.units)\n",
    "\n",
    "    def call(self, x, features, hidden):\n",
    "        # defining attention as a separate model\n",
    "        #context_vector, attention_weights = self.attention(features, hidden)\n",
    "        #print('decoder attention complete')\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        #print('decoder embedding complete')\n",
    "        #print(f'x.shape = {x.shape}')\n",
    "        #print(f'context_vector.shape = {context_vector.shape}')\n",
    "        \n",
    "        context_vector = np.zeros((1,45), np.float32)\n",
    "        #print(f'context_vector.shape = {context_vector.shape}')\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        #print('decoder embedding + context vector complete')\n",
    "        #print(f'x.shape = {x.shape}')\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        #print('decoder gru complete')\n",
    "\n",
    "        # shape == (batch_size, max_length, hidden_size)\n",
    "        x = self.fc1(output)\n",
    "        #print('decoder fc1 complete')\n",
    "\n",
    "        # x shape == (batch_size * max_length, hidden_size)\n",
    "        x = tf.reshape(x, (-1, x.shape[2]))\n",
    "        #print('decoder reshape complete')\n",
    "\n",
    "        # output shape == (batch_size * max_length, vocab)\n",
    "        x = self.fc2(x)\n",
    "        #print('decoder fc2 complete')\n",
    "\n",
    "        return x, state, #attention_weights\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "quKzY4IeSjqj"
   },
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder(embedding_dim)\n",
    "decoder = RNN_Decoder(embedding_dim, units, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "kI5g_iYrSjql"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "MASAvbV3Sjqn"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train_no_attention\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer = optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "8yQjrGWkSjqo"
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "      start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "      # restoring the latest checkpoint in checkpoint_path\n",
    "      ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "IE7pUZDGSjqq"
   },
   "outputs": [],
   "source": [
    "# adding this in a separate cell because if you run the training cell\n",
    "# many times, the loss_plot array will be reset\n",
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "JHXjLxYuSjqs"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(img_tensor, target):\n",
    "    loss = 0\n",
    "\n",
    "          # initializing the hidden state for each batch\n",
    "          # because the captions are not related from image to image\n",
    "    hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "    #print(f'hidden complete: {hidden}')\n",
    "\n",
    "    # Create a vector of all \\t indices to indicate the start of prediction\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['\\t']] * target.shape[0], 1)\n",
    "    #print(f'dec_input complete: {dec_input}')\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        features = encoder(img_tensor)\n",
    "        #print('encoder complete')\n",
    "        #print(f'features.shape = {features.shape}')\n",
    "\n",
    "        # iterate through timesteps to predict the i'th character\n",
    "        for i in range(1, target.shape[1]):\n",
    "            # passing the features through the decoder\n",
    "            predictions, hidden = decoder(dec_input, features, hidden)\n",
    "            #print('decoder complete')\n",
    "\n",
    "            loss += loss_function(target[:, i], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(target[:, i], 1)\n",
    "\n",
    "    total_loss = (loss / int(target.shape[1]))\n",
    "\n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hKZ-gQg4hmoZ"
   },
   "outputs": [],
   "source": [
    "image_dataset_encoded = tf.data.Dataset.from_tensor_slices((img_load, cap_vector)).batch(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7322,
     "status": "ok",
     "timestamp": 1605397126121,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "vZPAuWz8Sjqu",
    "outputId": "cacc9dc1-aae4-4391-dba4-b28245e0d454",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['cnn__encoder_1/dense_3/kernel:0', 'cnn__encoder_1/dense_3/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['cnn__encoder_1/dense_3/kernel:0', 'cnn__encoder_1/dense_3/bias:0'] when minimizing the loss.\n",
      "Epoch 3 Batch 0 Loss 2.0561\n",
      "Epoch 3 Batch 1 Loss 2.0410\n",
      "Epoch 3 Batch 2 Loss 2.0176\n",
      "Epoch 3 Batch 3 Loss 2.0092\n",
      "Epoch 3 Batch 4 Loss 1.9937\n",
      "Epoch 3 Batch 5 Loss 1.9837\n",
      "Epoch 3 Batch 6 Loss 1.9646\n",
      "Epoch 3 Batch 7 Loss 1.9498\n",
      "Epoch 3 Batch 8 Loss 1.9347\n",
      "Epoch 3 Batch 9 Loss 1.9198\n",
      "Epoch 3 Batch 10 Loss 1.9075\n",
      "Epoch 3 Batch 11 Loss 1.8941\n",
      "Epoch 3 Batch 12 Loss 1.8820\n",
      "Epoch 3 Batch 13 Loss 1.8684\n",
      "7000\n",
      "Epoch 3 Loss 0.003917\n",
      "Time taken for 1 epoch 17.473231077194214 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.8589\n",
      "Epoch 4 Batch 1 Loss 1.8511\n",
      "Epoch 4 Batch 2 Loss 1.8357\n",
      "Epoch 4 Batch 3 Loss 1.8322\n",
      "Epoch 4 Batch 4 Loss 1.8191\n",
      "Epoch 4 Batch 5 Loss 1.8178\n",
      "Epoch 4 Batch 6 Loss 1.8043\n",
      "Epoch 4 Batch 7 Loss 1.7972\n",
      "Epoch 4 Batch 8 Loss 1.7871\n",
      "Epoch 4 Batch 9 Loss 1.7834\n",
      "Epoch 4 Batch 10 Loss 1.7772\n",
      "Epoch 4 Batch 11 Loss 1.7705\n",
      "Epoch 4 Batch 12 Loss 1.7630\n",
      "Epoch 4 Batch 13 Loss 1.7561\n",
      "7000\n",
      "Epoch 4 Loss 0.003608\n",
      "Time taken for 1 epoch 11.509919881820679 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.7531\n",
      "Epoch 5 Batch 1 Loss 1.7513\n",
      "Epoch 5 Batch 2 Loss 1.7451\n",
      "Epoch 5 Batch 3 Loss 1.7453\n",
      "Epoch 5 Batch 4 Loss 1.7368\n",
      "Epoch 5 Batch 5 Loss 1.7396\n",
      "Epoch 5 Batch 6 Loss 1.7327\n",
      "Epoch 5 Batch 7 Loss 1.7304\n",
      "Epoch 5 Batch 8 Loss 1.7257\n",
      "Epoch 5 Batch 9 Loss 1.7255\n",
      "Epoch 5 Batch 10 Loss 1.7238\n",
      "Epoch 5 Batch 11 Loss 1.7210\n",
      "Epoch 5 Batch 12 Loss 1.7167\n",
      "Epoch 5 Batch 13 Loss 1.7132\n",
      "7000\n",
      "Epoch 5 Loss 0.003466\n",
      "Time taken for 1 epoch 10.952167987823486 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.7134\n",
      "Epoch 6 Batch 1 Loss 1.7128\n",
      "Epoch 6 Batch 2 Loss 1.7113\n",
      "Epoch 6 Batch 3 Loss 1.7116\n",
      "Epoch 6 Batch 4 Loss 1.7071\n",
      "Epoch 6 Batch 5 Loss 1.7092\n",
      "Epoch 6 Batch 6 Loss 1.7062\n",
      "Epoch 6 Batch 7 Loss 1.7059\n",
      "Epoch 6 Batch 8 Loss 1.7036\n",
      "Epoch 6 Batch 9 Loss 1.7041\n",
      "Epoch 6 Batch 10 Loss 1.7033\n",
      "Epoch 6 Batch 11 Loss 1.7024\n",
      "Epoch 6 Batch 12 Loss 1.7001\n",
      "Epoch 6 Batch 13 Loss 1.6987\n",
      "7000\n",
      "Epoch 6 Loss 0.003413\n",
      "Time taken for 1 epoch 10.89219617843628 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.6988\n",
      "Epoch 7 Batch 1 Loss 1.6986\n",
      "Epoch 7 Batch 2 Loss 1.6988\n",
      "Epoch 7 Batch 3 Loss 1.6985\n",
      "Epoch 7 Batch 4 Loss 1.6961\n",
      "Epoch 7 Batch 5 Loss 1.6968\n",
      "Epoch 7 Batch 6 Loss 1.6964\n",
      "Epoch 7 Batch 7 Loss 1.6962\n",
      "Epoch 7 Batch 8 Loss 1.6948\n",
      "Epoch 7 Batch 9 Loss 1.6957\n",
      "Epoch 7 Batch 10 Loss 1.6951\n",
      "Epoch 7 Batch 11 Loss 1.6947\n",
      "Epoch 7 Batch 12 Loss 1.6936\n",
      "Epoch 7 Batch 13 Loss 1.6935\n",
      "7000\n",
      "Epoch 7 Loss 0.003393\n",
      "Time taken for 1 epoch 13.371924877166748 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.6932\n",
      "Epoch 8 Batch 1 Loss 1.6929\n",
      "Epoch 8 Batch 2 Loss 1.6936\n",
      "Epoch 8 Batch 3 Loss 1.6929\n",
      "Epoch 8 Batch 4 Loss 1.6918\n",
      "Epoch 8 Batch 5 Loss 1.6916\n",
      "Epoch 8 Batch 6 Loss 1.6920\n",
      "Epoch 8 Batch 7 Loss 1.6917\n",
      "Epoch 8 Batch 8 Loss 1.6910\n",
      "Epoch 8 Batch 9 Loss 1.6920\n",
      "Epoch 8 Batch 10 Loss 1.6914\n",
      "Epoch 8 Batch 11 Loss 1.6910\n",
      "Epoch 8 Batch 12 Loss 1.6905\n",
      "Epoch 8 Batch 13 Loss 1.6910\n",
      "7000\n",
      "Epoch 8 Loss 0.003384\n",
      "Time taken for 1 epoch 11.207072973251343 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.6903\n",
      "Epoch 9 Batch 1 Loss 1.6902\n",
      "Epoch 9 Batch 2 Loss 1.6909\n",
      "Epoch 9 Batch 3 Loss 1.6902\n",
      "Epoch 9 Batch 4 Loss 1.6895\n",
      "Epoch 9 Batch 5 Loss 1.6893\n",
      "Epoch 9 Batch 6 Loss 1.6897\n",
      "Epoch 9 Batch 7 Loss 1.6892\n",
      "Epoch 9 Batch 8 Loss 1.6888\n",
      "Epoch 9 Batch 9 Loss 1.6899\n",
      "Epoch 9 Batch 10 Loss 1.6894\n",
      "Epoch 9 Batch 11 Loss 1.6890\n",
      "Epoch 9 Batch 12 Loss 1.6886\n",
      "Epoch 9 Batch 13 Loss 1.6892\n",
      "7000\n",
      "Epoch 9 Loss 0.003379\n",
      "Time taken for 1 epoch 10.457051038742065 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.6885\n",
      "Epoch 10 Batch 1 Loss 1.6886\n",
      "Epoch 10 Batch 2 Loss 1.6892\n",
      "Epoch 10 Batch 3 Loss 1.6887\n",
      "Epoch 10 Batch 4 Loss 1.6880\n",
      "Epoch 10 Batch 5 Loss 1.6879\n",
      "Epoch 10 Batch 6 Loss 1.6882\n",
      "Epoch 10 Batch 7 Loss 1.6877\n",
      "Epoch 10 Batch 8 Loss 1.6875\n",
      "Epoch 10 Batch 9 Loss 1.6886\n",
      "Epoch 10 Batch 10 Loss 1.6882\n",
      "Epoch 10 Batch 11 Loss 1.6877\n",
      "Epoch 10 Batch 12 Loss 1.6873\n",
      "Epoch 10 Batch 13 Loss 1.6879\n",
      "7000\n",
      "Epoch 10 Loss 0.003376\n",
      "Time taken for 1 epoch 10.320060014724731 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (img_tensor, target)) in enumerate(image_dataset_encoded):\n",
    "        batch_loss, t_loss = train_step(img_tensor, target)\n",
    "        total_loss += t_loss\n",
    "\n",
    "        if batch % 1 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                epoch + 1, batch, batch_loss / int(target.shape[1])))\n",
    "    # storing the epoch end loss value to plot later\n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        ckpt_manager.save() \n",
    "    print(num_steps)\n",
    "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                         total_loss/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 5485,
     "status": "ok",
     "timestamp": 1605397126122,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "lsSx6FGZZh3q",
    "outputId": "94b1a0e7-25ef-4bb5-e1ed-cdd2b0c113eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S60WeHNwdPDG"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "31N4XxAYcahR"
   },
   "outputs": [],
   "source": [
    "def evaluate(image):\n",
    "    attention_plot = np.zeros((max_length, attention_features_shape))\n",
    "\n",
    "    hidden = decoder.reset_state(batch_size=1)\n",
    "\n",
    "    temp_input = tf.expand_dims(image, 0)\n",
    "    #print(temp_input)\n",
    "    img_tensor_val = image_features_extract_model(temp_input)\n",
    "    #print(img_tensor_val)\n",
    "    img_tensor_val = tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))\n",
    "    #print(img_tensor_val)\n",
    "    \n",
    "    features = encoder(img_tensor_val)\n",
    "\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['\\t']], 0)\n",
    "    result = []\n",
    "\n",
    "    for i in range(max_length):\n",
    "        predictions, hidden = decoder(dec_input, features, hidden)\n",
    "        #attention_plot[i] = tf.reshape(attention_weights, (-1, ))\n",
    "\n",
    "        predicted_id = tf.random.categorical(predictions, 1)[0][0]\n",
    "        predicted_id = int(predicted_id)\n",
    "        result.append(tokenizer.index_word[predicted_id])\n",
    "        #print(tokenizer.index_word[predicted_id])\n",
    "        ind = np.argpartition(predictions, -4)[0][-4:]\n",
    "        #print(f'These are the top choices {\"\".join(tokenizer.index_word[c] for c in ind)}')\n",
    "        #print(f'This are the probabilities {predictions.numpy()[0,ind]}')\n",
    "\n",
    "        if tokenizer.index_word[predicted_id] == '\\n':\n",
    "            return result#, attention_plot\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    #attention_plot = attention_plot[:len(result), :]\n",
    "    return result#, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "CEEvzEL8dmsV"
   },
   "outputs": [],
   "source": [
    "def plot_attention(image, result, attention_plot):\n",
    "    \n",
    "    #-1 goes to zero\n",
    "    temp_image = np.array(image)\n",
    "    temp_image = (temp_image + 1) / 2\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    len_result = len(result)\n",
    "    for l in range(len_result):\n",
    "        temp_att = np.resize(attention_plot[l], (8, 8))\n",
    "        ax = fig.add_subplot(len_result//2, len_result//2, l+1)\n",
    "        ax.set_title(result[l])\n",
    "        img = ax.imshow(temp_image)\n",
    "        ax.imshow(temp_att, cmap='gray', alpha=0.6, extent=img.get_extent())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-GvV9Q9eaJh"
   },
   "source": [
    "Run attention_plot to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Caption: r k y p n q k 6\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(img_test[0])\n",
    "print ('Prediction Caption:', ' '.join(result))\n",
    "#plot_attention(img_test[0], result, attention_plot)\n",
    "# opening the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Caption: 3 z m p u 2 m k\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(img_test[9])\n",
    "print ('Prediction Caption:', ' '.join(result))\n",
    "#plot_attention(img_test[9], result, attention_plot)\n",
    "# opening the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Caption: 5 a p 0 s 9 g f\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(img_test[5])\n",
    "print ('Prediction Caption:', ' '.join(result))\n",
    "#plot_attention(img_test[5], result, attention_plot)\n",
    "# opening the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_results(images, labels, num_imgs=10):\n",
    "    for i in range(0, num_imgs):\n",
    "        result = evaluate(images[i])\n",
    "        print('Prediction Caption:', ' '.join(result))\n",
    "        print(f'Actual Caption: ', labels[i])\n",
    "        #plot_attention(images[i], result, attention_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Caption: t x c z p \n",
      "\n",
      "Actual Caption:  \t6j+4=3\n",
      "\n",
      "Prediction Caption: v = c 1 \n",
      "\n",
      "Actual Caption:  \t2p+5=9\n",
      "\n",
      "Prediction Caption: w <unk> e 7 p 3 2 b\n",
      "Actual Caption:  \t5t+2=9\n",
      "\n",
      "Prediction Caption: <unk> o m 6 x o 6 l\n",
      "Actual Caption:  \t9c+2=5\n",
      "\n",
      "Prediction Caption: i 0 n w m 8 5 9\n",
      "Actual Caption:  \t4n+7=0\n",
      "\n",
      "Prediction Caption: f u k z 2 3 m c\n",
      "Actual Caption:  \t8g+4=7\n",
      "\n",
      "Prediction Caption: d o i w 9 5 0 2\n",
      "Actual Caption:  \t7t+8=3\n",
      "\n",
      "Prediction Caption: a g t o y + n s\n",
      "Actual Caption:  \t4e+5=3\n",
      "\n",
      "Prediction Caption: 8 e u <unk> \n",
      "\n",
      "Actual Caption:  \t3f+1=5\n",
      "\n",
      "Prediction Caption: e i c o 0 w 1 w\n",
      "Actual Caption:  \t6o+7=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_results(img_test, img_test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Morgan Copy Image Captioning with Attention (Drive).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
