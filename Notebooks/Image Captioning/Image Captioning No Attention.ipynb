{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xUzM901Sjpe"
   },
   "source": [
    "# Image Captioning with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23950,
     "status": "ok",
     "timestamp": 1605553608791,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "rMgFop76Sjpf",
    "outputId": "b2cf6200-462f-466c-c514-b99318169097"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import image\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqP6UkWTSjpj"
   },
   "source": [
    "Loading the Data. The data consist of pictures and labels of linear functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1605553609779,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "08AiJm9zSjpk"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def load_images_from_folder(folder, n_imgs=-1):\n",
    "    images = []\n",
    "    image_nums = []\n",
    "    for filename in os.listdir(folder)[:n_imgs]:\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            image_nums.append(filename.strip('.png'))\n",
    "    return images, image_nums\n",
    "\n",
    "folder=\"../../../Math Equations/linear_fcns/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 45955,
     "status": "ok",
     "timestamp": 1605554061902,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "vBBKDvA8Sjpm"
   },
   "outputs": [],
   "source": [
    "images, fnames = load_images_from_folder(folder,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WYkOrKFFSjpp"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../../../Math Equations/linear_fcns/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JoZjytqMWTiR"
   },
   "outputs": [],
   "source": [
    "labels['img_number'] = labels['filename'].apply(lambda x: x.split('/')[-1].strip('.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1605395495815,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "vC3wCKPxWQaC",
    "outputId": "902efffe-60ca-411b-f507-a329adf0f01a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latex</th>\n",
       "      <th>filename</th>\n",
       "      <th>img_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0a+1=2</td>\n",
       "      <td>linear_fcns/images/0.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0b+1=2</td>\n",
       "      <td>linear_fcns/images/1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0c+1=2</td>\n",
       "      <td>linear_fcns/images/2.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0d+1=2</td>\n",
       "      <td>linear_fcns/images/3.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e+1=2</td>\n",
       "      <td>linear_fcns/images/4.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latex                  filename img_number\n",
       "0  0a+1=2  linear_fcns/images/0.png          0\n",
       "1  0b+1=2  linear_fcns/images/1.png          1\n",
       "2  0c+1=2  linear_fcns/images/2.png          2\n",
       "3  0d+1=2  linear_fcns/images/3.png          3\n",
       "4  0e+1=2  linear_fcns/images/4.png          4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DC-tLPESWAy5"
   },
   "outputs": [],
   "source": [
    "label_array = labels[labels['img_number'].isin(fnames)]['latex'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXR3M4QBSjpv"
   },
   "source": [
    "For the labels we need to add start and end tokens so the model can recognize what to write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NEzxzBX8Sjpv"
   },
   "outputs": [],
   "source": [
    "label_array = [f'\\t{la}\\n' for la in label_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHztSmQ_Sjpy"
   },
   "source": [
    "Let's reshape the images so we can plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1605395503599,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "9XdF3xaGSjpy",
    "outputId": "9b633ce9-2750-4b1c-e926-9f2b75a9d58f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 72, 360, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_for_split = images\n",
    "images = np.array(images)\n",
    "images = 255 - images\n",
    "# images = tf.image.rgb_to_grayscale(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff9d91b58d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQYvxF90Sjp3"
   },
   "source": [
    "Now we can process them and prepare them for inceptionv3 which is transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train, img_test, img_train_name, img_test_name = train_test_split(images, label_array, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mini = tf.image.resize_with_pad(img_train, 299, 299)\n",
    "img_test= tf.image.resize_with_pad(img_test, 299, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pE87-f9ESjp4"
   },
   "outputs": [],
   "source": [
    "img_mini = tf.keras.applications.inception_v3.preprocess_input(img_mini)\n",
    "img_test = tf.keras.applications.inception_v3.preprocess_input(img_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-8n1FtqSjp8"
   },
   "source": [
    "Now we can load the features of the inceptionv3 model as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mini0 = (img_mini[0] + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1605395508912,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "8uSNNnvdSjp6",
    "outputId": "c123a164-46bf-4b86-9368-f105029f9f0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff9d9237b90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUKklEQVR4nO3de2zX9b3H8ee7v0JLoWRcFBDwAAUTGYmI6HE7hsU5uXQzhS0zGHSdx60n2djmySRzM2Rujj88OdvRxUFWFMc2VJzTiHcoIcPFcAfLpWWgoFxqYcgEBHv7vc8fvy/s19LSX9vfpe7zeiTf/L6/z/f27qf0xed7aX/m7ohIuPJyXYCI5JZCQCRwCgGRwCkERAKnEBAJnEJAJHAZCwEzm2lme81sv5ndn6njiEjPWCaeEzCzGPA34FbgMLAZuMPd96T9YCLSI5kaCdwA7Hf3d929EXgGKMvQsUSkB/IztN+RwKGk94eBf+9oZTPTY4simfd3d7+sbWOmQqBTZlYBVOTq+CIBeq+9xkyFwBFgdNL7UVHbBe5eCVSCRgIiuZSpawKbgQlmNtbM+gJzgVUZOpaI9EBGRgLu3mxm84E3gBiwzN13Z+JYItIzGblF2OUidDogkg1b3X1q20Y9MSgSOIWASOAUAiKBUwiIBE4hIBI4hYBI4BQCIoFTCIgETiEgEjiFgEjgFAIigVMIiAROISASOIWASOAUAiKBUwiIBE4hIBI4hYBI4BQCIoFTCIgETiEgEjiFgEjgFAIigVMIiAROISASOIWASOAUAiKBUwiIBK5Hn0psZgeB00AL0OzuU81sMLASGAMcBG5395M9K1NEMiUdI4Gb3X1y0qed3g+sdfcJwNrovYj0Upk4HSgDlkfzy4HZGTiGiKRJT0PAgdVmttXMKqK2Ye5eF81/AAxrb0MzqzCzLWa2pYc1iEgP9OiaAHCTux8xs8uBNWZWm7zQ3d3MvL0N3b0SqAToaB0RybwejQTc/Uj0egx4AbgBqDezEQDR67GeFikimdPtEDCz/mZWfH4emA7sAlYB5dFq5cCLPS1SRDKnJ6cDw4AXzOz8fp5y99fNbDPwrJndA7wH3N7zMkUkU8w996fjuiYgkhVbk27lX6AnBkUCpxAQCZxCQCRwCgGRwCkERAKnEBAJnEJAJHAKAZHAKQREAqcQEAmcQkAkcAoBkcApBEQCpxAQCZxCQCRwCgGRwCkERAKnEBAJnEJAJHAKAZHAKQREAqcQEAmcQkAkcAoBkcApBEQCpxAQCZxCQCRwnYaAmS0zs2NmtiupbbCZrTGzfdHroKjdzOzXZrbfzKrNbEomixeRnktlJPA7YGabtvuBte4+AVgbvQeYBUyIpgpgSXrKFJFM6TQE3H098GGb5jJgeTS/HJid1P57T9gAfMbMRqSpVhHJgO5eExjm7nXR/AfAsGh+JHAoab3DUdtFzKzCzLaY2ZZu1iAiaZDf0x24u5uZd2O7SqASoDvbi0h6dHckUH9+mB+9HovajwCjk9YbFbWJSC/V3RBYBZRH8+XAi0nt34juEtwIfJR02iAivZG7X3ICngbqgCYS5/j3AENI3BXYB1QBg6N1DfgN8A6wE5ja2f6j7VyTJk0Zn7a09/Nn0Q9hTumagEhWbHX3qW0b9cSgSOAUAiKBUwiIBE4hIBI4hYBI4BQCIoFTCIgETiEgEjiFgEjgFAIigVMIiAROISASOIWASOAUAiKBUwiIBE4hIBI4hYBI4BQCIoFTCIgETiEgEjiFgEjgFAIigVMIiAROISASOIWASOAUAiKBUwiIBK7TEDCzZWZ2zMx2JbU9aGZHzGxHNJUmLfuxme03s71mNiNThYtIeqQyEvgdMLOd9v9z98nR9CqAmU0E5gKfjbZZbGaxdBUrIunXaQi4+3rgwxT3VwY84+4N7n4A2A/c0IP6RCTDenJNYL6ZVUenC4OitpHAoaR1DkdtItJL5XdzuyXAQ4BHr78E/rMrOzCzCqCim8dPi/z8fIqKisjLa52FZ8+epbGxMUdVXWzgwIEX1ZjM3Tl9+jTxeDyLVUFeXh4DBw4EoLm5mTNnzmT1+JIe3QoBd68/P29mS4GXo7dHgNFJq46K2trbRyVQGe3Du1NHT8RiMW655Ra+/vWvM2DAgAvtLS0tVFVV8fTTT/PJJ59ku6yLFBYW8rOf/YwRI0Z0uM7Zs2f56U9/yqFDhzpcJxNmzZrFXXfdBUBtbS2LFi2iqakpqzVIGrh7pxMwBtiV9H5E0vx/k7gOAIkLgm8DBcBY4F0glsL+PdvTlClTvLq62puamry5udnPnTvnTU1NHo/H/f333/d58+al/Zh5eXleUFDgsVgs5W2Ki4u9urraz507d9EUj8fd3f3EiRM+ceLErPbf9OnTfe/evX7e+vXrvbCwMOvfR01dmra0+/OXwg/o00Ad0ETiHP8e4A/ATqAaWEXrUHgAeAfYC8xKMWSy2hl5eXm+YMECj8fjfubMGX/00Ue9X79+XlFR4cePH/d4PO4rVqzw4uJiB9zMfMCAAT5o0KAOp6Kiok6PO3PmTD9x4oQvXLiwS/UWFBR4v379Wk3Dhw/348ePu7v7ww8/7Hl5eVnrvyFDhvgjjzzi586d87NnzyoEPj1TuyHQ6emAu9/RTvMTl1h/EbCos/3mUt++famoqMDMePbZZ/nRj37EJ598wuOPP87ll1/OQw89RGlpKePGjePtt9+muLiY733ve0yaNKnDfa5Zs4Ynn3zyfKi1KxaLUVhYSJ8+fbpUb0NDw0VtX/va1ygqKuLMmTO89957WbsekJ+fzx133EF5eTkffvghGzZs4Ktf/WpWji2Z0d0Lg/8ytm/ffuEiYDweZ+PGjQCYGf369QMSoXHdddcxbdq0C9uZGYMGDcLMOHnyJCtXrrxkAKRTSUkJ3/zmNyksLGTHjh1UVVV1uG6fPn0YMGAAZpbSvk+dOkVzc3OHy8ePH8+3vvUtCgoKePDBBxkyZIhC4FMu+BBo69ixY+zfv5+SkhLmz5/P9u3bOXHiBHfeeSf5+YnuisVifPGLX+Spp54iFouxceNG3nrrrazVOHr0aEpKSmhoaODJJ59k3759Ha57yy238NhjjzF06NCU9n3bbbfx5ptvtrusb9++rFixgkmTJvHoo4+ybNkyFixY0K2vQXoPhUAbNTU1VFVVMX78eAoKCgBwd86ePQskhsO33norDz30EHl5eaxfv54FCxZw7NixVvuJxWLccEPr56Suvvpq8vLyGDVqFJ/73OcutLs777//PkePHu20vn79+jFt2jQuu+wyTp8+zaFDhy45Ajl9+jS1tbUMGjSow3WSffzxx+22FxUVUV5ezrhx4zh06BDr1q1r9zRFPn0UAm0UFhZSXFzc7jIzo7S0lIcffpjx48fzxhtvsGDBAmpray9at3///qxatYpY7J9PTffp04eCggLmzp3L7NmzL7Q3NDSwaNEiHnvssU7rKyoqYtKkSfTv359t27bx2muvXXL9TZs2MW/evJRPBzq613/NNddw7733UlBQwHPPPcdbb72V9ecSJDMUAm1MnjyZsrIyGhoa2Lx5My0tLReW3Xbbbfz2t79l2LBhvPTSS1RUVFBfX9/ufhobG/njH//Y6iGfMWPGUFpays6dO9mwYcOF9ubmZvbs2ZNSfVdffTWlpaW0tLTw8ssvd/pQ08iRI/nSl7504fpGZ1544QUOHz7cqi0/P5/bb7+dcePG8Y9//IOTJ08yb968VqOdK664gu985zvU1NR0GkzSy6RyCy/TE1m+VVJYWOj79u1zd/fvf//7rW6vTZ8+3d3dT5486ddcc40DPnToUL/zzjv9nXfe8cbGRn/11Vf9qquu6vJxv/zlL/vHH3/sP//5z7td++uvv+7u7gcOHPDBgwendMy6ujpvbm5Oabr55psv2kd+fr5XVla2u35LS4u7u8fjcW9ubvaVK1d69PCXpt43de8W4b8id6e+vp6SkhLmzJnD6tWrqa2tZfjw4ReegDt58iQNDQ2MHTuWRx55hJkzZxKLxXj++ed54IEHLnkxLlOGDx/OddddB8DSpUv56KOPOt1m9+7dLFy4MOWRQHtfVzweZ+XKlezcubNVeywWY+bMmcyYMYN3332XxYsXU1NTk7W7JJIeQYZAY2Mjy5Yt4/Of/zxf+MIXWLp0KS+99BLXX389ZWVlAKxevZoDBw7wi1/8gtLSUvLz82lpaaG+vp45c+Zc2NfRo0d57rnnsvKI8be//W0GDhzI4cOH2bVrV0rn5AcPHuTxxx/v0XHj8Thr165l7dq1rdrz8/MZPHgwM2bM4OjRoyxevLhXPGotXRNkCLg7r7zyCn/605/4yle+wvXXX8+1115LXl4e8XicTZs2sXjxYvLz87nyyiuJx+MXzr3vvvvuVvvatGkTr7zySkr/+OPxOE1NTa2uM6RqypQpzJkzh5aWFrZv38727dt7xf+4LS0tNDY2XvLZAundggwBgPr6eu677z6qqqou+gWiv/zlL1RXVzN+/Hj++te/trqI11ZdXR3nzp1L6Zi1tbUsXLiQrVu3drne48ePs2TJEgoKCli3bl3Wf1moPfF4nDVr1nDq1CmOHj2qXx76lLLe8L9JLn6LUCRAW919attG/aFRkcApBEQCpxAQCZxCQCRwCgGRwCkERAKnEBAJnEJAJHAKAZHAKQREAqcQEAmcQkAkcAoBkcApBEQCpxAQCZxCQCRwCgGRwHUaAmY22szWmdkeM9ttZj+I2geb2Roz2xe9Dorazcx+bWb7zazazKZk+osQke5LZSTQDPzQ3ScCNwLfNbOJwP3AWnefAKyN3gPMAiZEUwWwJO1Vi0jadBoC7l7n7tui+dNADTASKAOWR6stB2ZH82XA7z1hA/AZMxuR7sJFJD26dE3AzMYA1wIbgWHuXhct+gAYFs2PBJL/FO7hqK3tvirMbIuZbelq0SKSPimHgJkNAP4M3Ovup5KXeeJPFnfpLwa7e6W7T23vr5+KSPakFAJm1odEAKxw9+ej5vrzw/zo9fxncx8BRidtPipqE5FeKJW7AwY8AdS4+6+SFq0CyqP5cuDFpPZvRHcJbgQ+SjptEJFeptMPHzGzm4A3gZ3A+Q+/+wmJ6wLPAlcC7wG3u/uHUWg8BswEzgJ3u/slz/v14SMiWdHuh4/oE4hEwqFPIBKRiykERAKnEBAJnEJAJHAKAZHAKQREAqcQEAmcQkAkcAoBkcApBEQCpxAQCZxCQCRwCgGRwCkERAKnEBAJnEJAJHAKAZHAKQREAqcQEAmcQkAkcAoBkcApBEQCpxAQCZxCQCRwCgGRwCkERAKnEBAJXCqfSjzazNaZ2R4z221mP4jaHzSzI2a2I5pKk7b5sZntN7O9ZjYjk1+AiPRMfgrrNAM/dPdtZlYMbDWzNdGy/3P3/01e2cwmAnOBzwJXAFVmdpW7t6SzcBFJj05HAu5e5+7bovnTQA0w8hKblAHPuHuDux8A9gM3pKNYEUm/Ll0TMLMxwLXAxqhpvplVm9kyMxsUtY0EDiVtdphLh4aI5FDKIWBmA4A/A/e6+ylgCVACTAbqgF925cBmVmFmW8xsS1e2E5H0SikEzKwPiQBY4e7PA7h7vbu3uHscWMo/h/xHgNFJm4+K2lpx90p3n+ruU3vyBYhIz6Ryd8CAJ4Aad/9VUvuIpNXmALui+VXAXDMrMLOxwARgU/pKFpF0SuXuwH8AdwE7zWxH1PYT4A4zmww4cBD4LwB3321mzwJ7SNxZ+K7uDIj0Xubuua4BM8t9ESL/+ra2d/qtJwZFAqcQEAmcQkAkcAoBkcApBEQCpxAQCZxCQCRwCgGRwCkERAKnEBAJnEJAJHAKAZHAKQREAqcQEAmcQkAkcAoBkcApBEQCpxAQCZxCQCRwCgGRwCkERAKnEBAJnEJAJHAKAZHAKQREAqcQEAmcQkAkcAoBkcApBEQCpxAQCVx+rguI/B34OHrtLYaiejrT22pSPZf2b+01mrtnu5B2mdmW9j47PVdUT+d6W02qp3t0OiASOIWASOB6UwhU5rqANlRP53pbTaqnG3rNNQERyY3eNBIQkRzIeQiY2Uwz22tm+83s/hzVcNDMdprZDjPbErUNNrM1ZrYveh2U4RqWmdkxM9uV1NZuDZbw66jPqs1sSpbqedDMjkT9tMPMSpOW/TiqZ6+ZzchAPaPNbJ2Z7TGz3Wb2g6g9l33UUU0566ducfecTUAMeAcYB/QF3gYm5qCOg8DQNm3/A9wfzd8PPJzhGqYBU4BdndUAlAKvAQbcCGzMUj0PAve1s+7E6HtXAIyNvqexNNczApgSzRcDf4uOm8s+6qimnPVTd6ZcjwRuAPa7+7vu3gg8A5TluKbzyoDl0fxyYHYmD+bu64EPU6yhDPi9J2wAPmNmI7JQT0fKgGfcvcHdDwD7SXxv01lPnbtvi+ZPAzXASHLbRx3V1JGM91N35DoERgKHkt4f5tKdmCkOrDazrWZWEbUNc/e6aP4DYFgO6uqohlz22/xoeL0s6RQpq/WY2RjgWmAjvaSP2tQEvaCfUpXrEOgtbnL3KcAs4LtmNi15oSfGcjm9jdIbagCWACXAZKAO+GW2CzCzAcCfgXvd/VTyslz1UTs15byfuiLXIXAEGJ30flTUllXufiR6PQa8QGKIVn9++Bi9Hst2XZeoISf95u717t7i7nFgKf8cymalHjPrQ+KHbYW7Px8157SP2qsp1/3UVbkOgc3ABDMba2Z9gbnAqmwWYGb9zaz4/DwwHdgV1VEerVYOvJjNuiId1bAK+EZ0BfxG4KOkIXHGtDmnnkOin87XM9fMCsxsLDAB2JTmYxvwBFDj7r9KWpSzPuqoplz2U7fk+sokiau4fyNxpfSBHBx/HIkrtm8Du8/XAAwB1gL7gCpgcIbreJrE0LGJxLniPR3VQOKK92+iPtsJTM1SPX+IjldN4h/0iKT1H4jq2QvMykA9N5EY6lcDO6KpNMd91FFNOeun7kx6YlAkcLk+HRCRHFMIiAROISASOIWASOAUAiKBUwiIBE4hIBI4hYBI4P4f/TH+Ae8vON8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.squeeze(img_mini0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hgB8p8KZSjp8"
   },
   "outputs": [],
   "source": [
    "image_model = tf.keras.applications.InceptionV3(include_top=False,\n",
    "                                                weights='imagenet')\n",
    "new_input = image_model.input\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "\n",
    "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "llWCIcu3Sjp_"
   },
   "outputs": [],
   "source": [
    "# Feel free to change batch_size according to your system configuration\n",
    "image_dataset = tf.data.Dataset.from_tensor_slices((img_mini, img_train_name)).batch(500)#(img_mini, label_array)).batch(1)\n",
    "c = 1\n",
    "\n",
    "for img, label in image_dataset:\n",
    "    batch_features = image_features_extract_model(img)\n",
    "    batch_features = tf.reshape(batch_features,\n",
    "                              (batch_features.shape[0], -1, batch_features.shape[3]))\n",
    "  \n",
    "    p = f'../Batch Features Train/batch_features{c}'\n",
    "    c = c+1 \n",
    "     #path_of_feature = p.numpy().decode(\"utf-8\")\n",
    "    np.save(p, batch_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iKq5_-oTP22q"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Batch Features Train/batch_features15.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f04f2bd55223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Batch Features Train/batch_features1.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../Batch Features Train/batch_features{i}.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimg_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Batch Features Train/batch_features15.npy'"
     ]
    }
   ],
   "source": [
    "img_load = np.load('../Batch Features Train/batch_features1.npy')\n",
    "for i in range(2,21):\n",
    "    img_add = np.load(f'../Batch Features Train/batch_features{i}.npy')\n",
    "    img_load = np.concatenate((img_load, img_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1605396800358,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "js8_OsgYQLM3",
    "outputId": "cda0393f-c083-4bfd-96f5-e5e67e122071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 64, 2048)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_load.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dywlI7LUSjqC"
   },
   "source": [
    "### Tokenizing the labels\n",
    "\n",
    "Now we can pad the labels to make sure they are all the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "xPgRuUgBbnPJ"
   },
   "outputs": [],
   "source": [
    "# Find the maximum length of any caption in our dataset\n",
    "def calc_max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "Gipm5btLaNTb"
   },
   "outputs": [],
   "source": [
    "# Choose the top 5000 words from the vocabulary\n",
    "top_k = 41\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n",
    "                                                  oov_token=\"<unk>\",\n",
    "                                                  filters=' ',\n",
    "                                                  char_level=True)\n",
    "tokenizer.fit_on_texts(img_train_name)#label_array)\n",
    "train_seqs = tokenizer.texts_to_sequences(img_train_name)\n",
    "\n",
    "# Padding\n",
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "\n",
    "# Create the tokenized vectors\n",
    "train_seqs = tokenizer.texts_to_sequences(img_train_name)\n",
    "\n",
    "# Pad each vector to the max_length of the captions\n",
    "# If you do not provide a max_length value, pad_sequences calculates it automatically\n",
    "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')\n",
    "\n",
    "# Calculates the max_length, which is used to store the attention weights\n",
    "max_length = calc_max_length(train_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1605396804461,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "YfFg62gAcaL9",
    "outputId": "2f57f655-d469-4ca3-c192-68bd3b2e5087"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_words': 41,\n",
       " 'filters': ' ',\n",
       " 'lower': True,\n",
       " 'split': ' ',\n",
       " 'char_level': True,\n",
       " 'oov_token': '<unk>',\n",
       " 'document_count': 7000,\n",
       " 'word_counts': '{\"\\\\t\": 7000, \"2\": 1977, \"c\": 259, \"+\": 7000, \"0\": 2048, \"=\": 7000, \"9\": 2184, \"\\\\n\": 7000, \"8\": 2134, \"k\": 261, \"3\": 2070, \"4\": 2124, \"7\": 2136, \"i\": 290, \"6\": 2163, \"s\": 264, \"5\": 2132, \"r\": 286, \"1\": 2032, \"o\": 266, \"j\": 271, \"q\": 269, \"n\": 285, \"a\": 273, \"t\": 265, \"v\": 280, \"m\": 291, \"b\": 256, \"d\": 251, \"y\": 259, \"z\": 251, \"w\": 254, \"f\": 258, \"g\": 270, \"h\": 268, \"x\": 261, \"p\": 285, \"l\": 284, \"u\": 271, \"e\": 272}',\n",
       " 'word_docs': '{\"+\": 7000, \"\\\\n\": 7000, \"=\": 7000, \"c\": 259, \"9\": 2184, \"0\": 2048, \"\\\\t\": 7000, \"2\": 1977, \"4\": 2124, \"8\": 2134, \"3\": 2070, \"k\": 261, \"6\": 2163, \"7\": 2136, \"i\": 290, \"s\": 264, \"1\": 2032, \"5\": 2132, \"r\": 286, \"o\": 266, \"j\": 271, \"q\": 269, \"n\": 285, \"a\": 273, \"t\": 265, \"v\": 280, \"m\": 291, \"b\": 256, \"d\": 251, \"y\": 259, \"z\": 251, \"w\": 254, \"f\": 258, \"g\": 270, \"h\": 268, \"x\": 261, \"p\": 285, \"l\": 284, \"u\": 271, \"e\": 272}',\n",
       " 'index_docs': '{\"3\": 7000, \"5\": 7000, \"4\": 7000, \"35\": 259, \"6\": 2184, \"13\": 2048, \"2\": 7000, \"15\": 1977, \"11\": 2124, \"9\": 2134, \"12\": 2070, \"33\": 261, \"7\": 2163, \"8\": 2136, \"17\": 290, \"32\": 264, \"14\": 2032, \"10\": 2132, \"18\": 286, \"30\": 266, \"25\": 271, \"28\": 269, \"19\": 285, \"23\": 273, \"31\": 265, \"22\": 280, \"16\": 291, \"38\": 256, \"40\": 251, \"36\": 259, \"41\": 251, \"39\": 254, \"37\": 258, \"27\": 270, \"29\": 268, \"34\": 261, \"20\": 285, \"21\": 284, \"26\": 271, \"24\": 272}',\n",
       " 'index_word': '{\"1\": \"<unk>\", \"2\": \"\\\\t\", \"3\": \"+\", \"4\": \"=\", \"5\": \"\\\\n\", \"6\": \"9\", \"7\": \"6\", \"8\": \"7\", \"9\": \"8\", \"10\": \"5\", \"11\": \"4\", \"12\": \"3\", \"13\": \"0\", \"14\": \"1\", \"15\": \"2\", \"16\": \"m\", \"17\": \"i\", \"18\": \"r\", \"19\": \"n\", \"20\": \"p\", \"21\": \"l\", \"22\": \"v\", \"23\": \"a\", \"24\": \"e\", \"25\": \"j\", \"26\": \"u\", \"27\": \"g\", \"28\": \"q\", \"29\": \"h\", \"30\": \"o\", \"31\": \"t\", \"32\": \"s\", \"33\": \"k\", \"34\": \"x\", \"35\": \"c\", \"36\": \"y\", \"37\": \"f\", \"38\": \"b\", \"39\": \"w\", \"40\": \"d\", \"41\": \"z\", \"0\": \"<pad>\"}',\n",
       " 'word_index': '{\"<unk>\": 1, \"\\\\t\": 2, \"+\": 3, \"=\": 4, \"\\\\n\": 5, \"9\": 6, \"6\": 7, \"7\": 8, \"8\": 9, \"5\": 10, \"4\": 11, \"3\": 12, \"0\": 13, \"1\": 14, \"2\": 15, \"m\": 16, \"i\": 17, \"r\": 18, \"n\": 19, \"p\": 20, \"l\": 21, \"v\": 22, \"a\": 23, \"e\": 24, \"j\": 25, \"u\": 26, \"g\": 27, \"q\": 28, \"h\": 29, \"o\": 30, \"t\": 31, \"s\": 32, \"k\": 33, \"x\": 34, \"c\": 35, \"y\": 36, \"f\": 37, \"b\": 38, \"w\": 39, \"d\": 40, \"z\": 41, \"<pad>\": 0}'}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1605396805750,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "GhqB3K30dMEo",
    "outputId": "aa4eee8d-77a9-4033-c9e3-2fea59b698fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1605396806687,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "QKIAGkIIb5ty",
    "outputId": "ddfd8187-4314-40ca-f60f-abd639d21457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0i+1=2\n",
      " -> [2, 15, 35, 3, 13, 4, 6, 5]\n"
     ]
    }
   ],
   "source": [
    "print(f'{label_array[0]} -> {train_seqs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1605396807076,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "wWBs6Njidhy4",
    "outputId": "c72990bc-4ddb-4444-ecfe-89622e4d5e17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 15, 35, 3, 13, 4, 6, 5]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "char_to_int_map = tokenizer.get_config()['word_index']\n",
    "char_to_int_map = json.loads(char_to_int_map)\n",
    "[char_to_int_map[c] for c in img_train_name[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "dmak8HTlSjqT"
   },
   "outputs": [],
   "source": [
    "# Feel free to change these parameters according to your system's configuration\n",
    "embedding_dim = 45\n",
    "units = 32\n",
    "vocab_size = top_k + 1\n",
    "num_steps = len(img_train) // 1\n",
    "# Shape of the vector extracted from InceptionV3 is (64, 2048)\n",
    "# These two variables represent that vector shape\n",
    "features_shape = 2048\n",
    "attention_features_shape = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8xkSSS7Sjqb"
   },
   "source": [
    "## Model\n",
    "\n",
    "Below we are defining the attention, the encoder and the decoder. The encoder is just a fully connected layer from the features already extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "f7L_cEJzSjqc"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n",
    "\n",
    "        # hidden shape == (batch_size, hidden_size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        # attention_hidden_layer shape == (batch_size, 64, units)\n",
    "        attention_hidden_layer = (tf.nn.tanh(self.W1(features) +\n",
    "                                             self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # score shape == (batch_size, 64, 1)\n",
    "        # This gives you an unnormalized score for each image feature.\n",
    "        score = self.V(attention_hidden_layer)\n",
    "\n",
    "        # attention_weights shape == (batch_size, 64, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "Eij3DZsYSjqe"
   },
   "outputs": [],
   "source": [
    "class CNN_Encoder(tf.keras.Model):\n",
    "    # Since you have already extracted the features and dumped it using pickle\n",
    "    # This encoder passes those features through a Fully connected layer\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        # shape after fc == (batch_size, 64, embedding_dim)\n",
    "        self.fc = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc(x)\n",
    "        #print(f'This is x: {x}')\n",
    "        x = tf.nn.relu(x)\n",
    "        #print(f'This is x: {x}')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "dLl75ZtPSjqh"
   },
   "outputs": [],
   "source": [
    "class RNN_Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units, vocab_size):\n",
    "        super(RNN_Decoder, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc1 = tf.keras.layers.Dense(self.units)\n",
    "        self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        #self.attention = BahdanauAttention(self.units)\n",
    "\n",
    "    def call(self, x, features, hidden):\n",
    "        # defining attention as a separate model\n",
    "        #context_vector, attention_weights = self.attention(features, hidden)\n",
    "        #print('decoder attention complete')\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        #print('decoder embedding complete')\n",
    "        #print(f'x.shape = {x.shape}')\n",
    "        #print(f'context_vector.shape = {context_vector.shape}')\n",
    "        \n",
    "        context_vector = np.zeros((1,45), np.float32)\n",
    "        #print(f'context_vector.shape = {context_vector.shape}')\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        #print('decoder embedding + context vector complete')\n",
    "        #print(f'x.shape = {x.shape}')\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        #print('decoder gru complete')\n",
    "\n",
    "        # shape == (batch_size, max_length, hidden_size)\n",
    "        x = self.fc1(output)\n",
    "        #print('decoder fc1 complete')\n",
    "\n",
    "        # x shape == (batch_size * max_length, hidden_size)\n",
    "        x = tf.reshape(x, (-1, x.shape[2]))\n",
    "        #print('decoder reshape complete')\n",
    "\n",
    "        # output shape == (batch_size * max_length, vocab)\n",
    "        x = self.fc2(x)\n",
    "        #print('decoder fc2 complete')\n",
    "\n",
    "        return x, state, #attention_weights\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "quKzY4IeSjqj"
   },
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder(embedding_dim)\n",
    "decoder = RNN_Decoder(embedding_dim, units, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "kI5g_iYrSjql"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "MASAvbV3Sjqn"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train_no_attention\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer = optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "8yQjrGWkSjqo"
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "      start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "      # restoring the latest checkpoint in checkpoint_path\n",
    "      ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "IE7pUZDGSjqq"
   },
   "outputs": [],
   "source": [
    "# adding this in a separate cell because if you run the training cell\n",
    "# many times, the loss_plot array will be reset\n",
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "JHXjLxYuSjqs"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(img_tensor, target):\n",
    "    loss = 0\n",
    "\n",
    "          # initializing the hidden state for each batch\n",
    "          # because the captions are not related from image to image\n",
    "    hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "    #print(f'hidden complete: {hidden}')\n",
    "\n",
    "    # Create a vector of all \\t indices to indicate the start of prediction\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['\\t']] * target.shape[0], 1)\n",
    "    #print(f'dec_input complete: {dec_input}')\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        features = encoder(img_tensor)\n",
    "        #print('encoder complete')\n",
    "        #print(f'features.shape = {features.shape}')\n",
    "\n",
    "        # iterate through timesteps to predict the i'th character\n",
    "        for i in range(1, target.shape[1]):\n",
    "            # passing the features through the decoder\n",
    "            predictions, hidden = decoder(dec_input, features, hidden)\n",
    "            #print('decoder complete')\n",
    "\n",
    "            loss += loss_function(target[:, i], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(target[:, i], 1)\n",
    "\n",
    "    total_loss = (loss / int(target.shape[1]))\n",
    "\n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "hKZ-gQg4hmoZ"
   },
   "outputs": [],
   "source": [
    "image_dataset_encoded = tf.data.Dataset.from_tensor_slices((img_load, cap_vector)).batch(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7322,
     "status": "ok",
     "timestamp": 1605397126121,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "vZPAuWz8Sjqu",
    "outputId": "cacc9dc1-aae4-4391-dba4-b28245e0d454",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['cnn__encoder_19/dense_69/kernel:0', 'cnn__encoder_19/dense_69/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['cnn__encoder_19/dense_69/kernel:0', 'cnn__encoder_19/dense_69/bias:0'] when minimizing the loss.\n",
      "Epoch 1 Batch 0 Loss 3.2697\n",
      "Epoch 1 Batch 1 Loss 3.2665\n",
      "Epoch 1 Batch 2 Loss 3.2629\n",
      "Epoch 1 Batch 3 Loss 3.2590\n",
      "Epoch 1 Batch 4 Loss 3.2552\n",
      "Epoch 1 Batch 5 Loss 3.2517\n",
      "Epoch 1 Batch 6 Loss 3.2471\n",
      "Epoch 1 Batch 7 Loss 3.2435\n",
      "Epoch 1 Batch 8 Loss 3.2387\n",
      "Epoch 1 Batch 9 Loss 3.2334\n",
      "Epoch 1 Batch 10 Loss 3.2284\n",
      "Epoch 1 Batch 11 Loss 3.2237\n",
      "Epoch 1 Batch 12 Loss 3.2174\n",
      "Epoch 1 Batch 13 Loss 3.2116\n",
      "7000\n",
      "Epoch 1 Loss 0.006487\n",
      "Time taken for 1 epoch 18.39346194267273 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 3.2052\n",
      "Epoch 2 Batch 1 Loss 3.1989\n",
      "Epoch 2 Batch 2 Loss 3.1915\n",
      "Epoch 2 Batch 3 Loss 3.1839\n",
      "Epoch 2 Batch 4 Loss 3.1755\n",
      "Epoch 2 Batch 5 Loss 3.1682\n",
      "Epoch 2 Batch 6 Loss 3.1585\n",
      "Epoch 2 Batch 7 Loss 3.1510\n",
      "Epoch 2 Batch 8 Loss 3.1401\n",
      "Epoch 2 Batch 9 Loss 3.1283\n",
      "Epoch 2 Batch 10 Loss 3.1177\n",
      "Epoch 2 Batch 11 Loss 3.1080\n",
      "Epoch 2 Batch 12 Loss 3.0937\n",
      "Epoch 2 Batch 13 Loss 3.0803\n",
      "7000\n",
      "Epoch 2 Loss 0.006300\n",
      "Time taken for 1 epoch 11.807871103286743 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 3.0670\n",
      "Epoch 3 Batch 1 Loss 3.0527\n",
      "Epoch 3 Batch 2 Loss 3.0359\n",
      "Epoch 3 Batch 3 Loss 3.0199\n",
      "Epoch 3 Batch 4 Loss 3.0019\n",
      "Epoch 3 Batch 5 Loss 2.9864\n",
      "Epoch 3 Batch 6 Loss 2.9664\n",
      "Epoch 3 Batch 7 Loss 2.9511\n",
      "Epoch 3 Batch 8 Loss 2.9287\n",
      "Epoch 3 Batch 9 Loss 2.9049\n",
      "Epoch 3 Batch 10 Loss 2.8849\n",
      "Epoch 3 Batch 11 Loss 2.8678\n",
      "Epoch 3 Batch 12 Loss 2.8404\n",
      "Epoch 3 Batch 13 Loss 2.8161\n",
      "7000\n",
      "Epoch 3 Loss 0.005903\n",
      "Time taken for 1 epoch 13.586840152740479 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.7939\n",
      "Epoch 4 Batch 1 Loss 2.7698\n",
      "Epoch 4 Batch 2 Loss 2.7419\n",
      "Epoch 4 Batch 3 Loss 2.7184\n",
      "Epoch 4 Batch 4 Loss 2.6921\n",
      "Epoch 4 Batch 5 Loss 2.6715\n",
      "Epoch 4 Batch 6 Loss 2.6454\n",
      "Epoch 4 Batch 7 Loss 2.6289\n",
      "Epoch 4 Batch 8 Loss 2.6017\n",
      "Epoch 4 Batch 9 Loss 2.5751\n",
      "Epoch 4 Batch 10 Loss 2.5567\n",
      "Epoch 4 Batch 11 Loss 2.5448\n",
      "Epoch 4 Batch 12 Loss 2.5183\n",
      "Epoch 4 Batch 13 Loss 2.4997\n",
      "7000\n",
      "Epoch 4 Loss 0.005280\n",
      "Time taken for 1 epoch 13.00245213508606 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 2.4858\n",
      "Epoch 5 Batch 1 Loss 2.4685\n",
      "Epoch 5 Batch 2 Loss 2.4500\n",
      "Epoch 5 Batch 3 Loss 2.4378\n",
      "Epoch 5 Batch 4 Loss 2.4226\n",
      "Epoch 5 Batch 5 Loss 2.4119\n",
      "Epoch 5 Batch 6 Loss 2.3983\n",
      "Epoch 5 Batch 7 Loss 2.3915\n",
      "Epoch 5 Batch 8 Loss 2.3752\n",
      "Epoch 5 Batch 9 Loss 2.3585\n",
      "Epoch 5 Batch 10 Loss 2.3461\n",
      "Epoch 5 Batch 11 Loss 2.3360\n",
      "Epoch 5 Batch 12 Loss 2.3176\n",
      "Epoch 5 Batch 13 Loss 2.3038\n",
      "7000\n",
      "Epoch 5 Loss 0.004786\n",
      "Time taken for 1 epoch 13.328824043273926 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 2.2888\n",
      "Epoch 6 Batch 1 Loss 2.2727\n",
      "Epoch 6 Batch 2 Loss 2.2570\n",
      "Epoch 6 Batch 3 Loss 2.2401\n",
      "Epoch 6 Batch 4 Loss 2.2206\n",
      "Epoch 6 Batch 5 Loss 2.2044\n",
      "Epoch 6 Batch 6 Loss 2.1875\n",
      "Epoch 6 Batch 7 Loss 2.1745\n",
      "Epoch 6 Batch 8 Loss 2.1575\n",
      "Epoch 6 Batch 9 Loss 2.1386\n",
      "Epoch 6 Batch 10 Loss 2.1198\n",
      "Epoch 6 Batch 11 Loss 2.1037\n",
      "Epoch 6 Batch 12 Loss 2.0883\n",
      "Epoch 6 Batch 13 Loss 2.0733\n",
      "7000\n",
      "Epoch 6 Loss 0.004361\n",
      "Time taken for 1 epoch 12.109561920166016 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.0550\n",
      "Epoch 7 Batch 1 Loss 2.0416\n",
      "Epoch 7 Batch 2 Loss 2.0273\n",
      "Epoch 7 Batch 3 Loss 2.0090\n",
      "Epoch 7 Batch 4 Loss 1.9891\n",
      "Epoch 7 Batch 5 Loss 1.9764\n",
      "Epoch 7 Batch 6 Loss 1.9595\n",
      "Epoch 7 Batch 7 Loss 1.9493\n",
      "Epoch 7 Batch 8 Loss 1.9352\n",
      "Epoch 7 Batch 9 Loss 1.9220\n",
      "Epoch 7 Batch 10 Loss 1.9056\n",
      "Epoch 7 Batch 11 Loss 1.8946\n",
      "Epoch 7 Batch 12 Loss 1.8840\n",
      "Epoch 7 Batch 13 Loss 1.8713\n",
      "7000\n",
      "Epoch 7 Loss 0.003917\n",
      "Time taken for 1 epoch 11.961374998092651 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.8598\n",
      "Epoch 8 Batch 1 Loss 1.8520\n",
      "Epoch 8 Batch 2 Loss 1.8428\n",
      "Epoch 8 Batch 3 Loss 1.8309\n",
      "Epoch 8 Batch 4 Loss 1.8170\n",
      "Epoch 8 Batch 5 Loss 1.8131\n",
      "Epoch 8 Batch 6 Loss 1.8005\n",
      "Epoch 8 Batch 7 Loss 1.7957\n",
      "Epoch 8 Batch 8 Loss 1.7869\n",
      "Epoch 8 Batch 9 Loss 1.7838\n",
      "Epoch 8 Batch 10 Loss 1.7755\n",
      "Epoch 8 Batch 11 Loss 1.7711\n",
      "Epoch 8 Batch 12 Loss 1.7668\n",
      "Epoch 8 Batch 13 Loss 1.7580\n",
      "7000\n",
      "Epoch 8 Loss 0.003608\n",
      "Time taken for 1 epoch 9.875818967819214 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.7546\n",
      "Epoch 9 Batch 1 Loss 1.7514\n",
      "Epoch 9 Batch 2 Loss 1.7497\n",
      "Epoch 9 Batch 3 Loss 1.7442\n",
      "Epoch 9 Batch 4 Loss 1.7361\n",
      "Epoch 9 Batch 5 Loss 1.7377\n",
      "Epoch 9 Batch 6 Loss 1.7299\n",
      "Epoch 9 Batch 7 Loss 1.7276\n",
      "Epoch 9 Batch 8 Loss 1.7247\n",
      "Epoch 9 Batch 9 Loss 1.7258\n",
      "Epoch 9 Batch 10 Loss 1.7224\n",
      "Epoch 9 Batch 11 Loss 1.7196\n",
      "Epoch 9 Batch 12 Loss 1.7202\n",
      "Epoch 9 Batch 13 Loss 1.7154\n",
      "7000\n",
      "Epoch 9 Loss 0.003466\n",
      "Time taken for 1 epoch 9.98300814628601 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.7140\n",
      "Epoch 10 Batch 1 Loss 1.7133\n",
      "Epoch 10 Batch 2 Loss 1.7144\n",
      "Epoch 10 Batch 3 Loss 1.7108\n",
      "Epoch 10 Batch 4 Loss 1.7070\n",
      "Epoch 10 Batch 5 Loss 1.7089\n",
      "Epoch 10 Batch 6 Loss 1.7049\n",
      "Epoch 10 Batch 7 Loss 1.7034\n",
      "Epoch 10 Batch 8 Loss 1.7030\n",
      "Epoch 10 Batch 9 Loss 1.7041\n",
      "Epoch 10 Batch 10 Loss 1.7027\n",
      "Epoch 10 Batch 11 Loss 1.7010\n",
      "Epoch 10 Batch 12 Loss 1.7019\n",
      "Epoch 10 Batch 13 Loss 1.6996\n",
      "7000\n",
      "Epoch 10 Loss 0.003413\n",
      "Time taken for 1 epoch 9.93195629119873 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (img_tensor, target)) in enumerate(image_dataset_encoded):\n",
    "        batch_loss, t_loss = train_step(img_tensor, target)\n",
    "        total_loss += t_loss\n",
    "\n",
    "        if batch % 1 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                epoch + 1, batch, batch_loss / int(target.shape[1])))\n",
    "    # storing the epoch end loss value to plot later\n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        ckpt_manager.save() \n",
    "    print(num_steps)\n",
    "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                         total_loss/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 5485,
     "status": "ok",
     "timestamp": 1605397126122,
     "user": {
      "displayName": "Morgan Allen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaNMWmr2TlLrY_MBSDquiSqhgTuK8vCNzY4tLH=s64",
      "userId": "12026828979516915336"
     },
     "user_tz": 360
    },
    "id": "lsSx6FGZZh3q",
    "outputId": "94b1a0e7-25ef-4bb5-e1ed-cdd2b0c113eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S60WeHNwdPDG"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "id": "31N4XxAYcahR"
   },
   "outputs": [],
   "source": [
    "def evaluate(image):\n",
    "    attention_plot = np.zeros((max_length, attention_features_shape))\n",
    "\n",
    "    hidden = decoder.reset_state(batch_size=1)\n",
    "\n",
    "    temp_input = tf.expand_dims(image, 0)\n",
    "    #print(temp_input)\n",
    "    img_tensor_val = image_features_extract_model(temp_input)\n",
    "    #print(img_tensor_val)\n",
    "    img_tensor_val = tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))\n",
    "    #print(img_tensor_val)\n",
    "    \n",
    "    features = encoder(img_tensor_val)\n",
    "\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['\\t']], 0)\n",
    "    result = []\n",
    "\n",
    "    for i in range(max_length):\n",
    "        predictions, hidden = decoder(dec_input, features, hidden)\n",
    "        #attention_plot[i] = tf.reshape(attention_weights, (-1, ))\n",
    "\n",
    "        predicted_id = tf.random.categorical(predictions, 1)[0][0]\n",
    "        predicted_id = int(predicted_id)\n",
    "        result.append(tokenizer.index_word[predicted_id])\n",
    "        #print(tokenizer.index_word[predicted_id])\n",
    "        ind = np.argpartition(predictions, -4)[0][-4:]\n",
    "        #print(f'These are the top choices {\"\".join(tokenizer.index_word[c] for c in ind)}')\n",
    "        #print(f'This are the probabilities {predictions.numpy()[0,ind]}')\n",
    "\n",
    "        if tokenizer.index_word[predicted_id] == '\\n':\n",
    "            return result#, attention_plot\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    #attention_plot = attention_plot[:len(result), :]\n",
    "    return result#, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "CEEvzEL8dmsV"
   },
   "outputs": [],
   "source": [
    "def plot_attention(image, result, attention_plot):\n",
    "    \n",
    "    #-1 goes to zero\n",
    "    temp_image = np.array(image)\n",
    "    temp_image = (temp_image + 1) / 2\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    len_result = len(result)\n",
    "    for l in range(len_result):\n",
    "        temp_att = np.resize(attention_plot[l], (8, 8))\n",
    "        ax = fig.add_subplot(len_result//2, len_result//2, l+1)\n",
    "        ax.set_title(result[l])\n",
    "        img = ax.imshow(temp_image)\n",
    "        ax.imshow(temp_att, cmap='gray', alpha=0.6, extent=img.get_extent())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-GvV9Q9eaJh"
   },
   "source": [
    "Run attention_plot to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Caption: k 3 s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(img_test[0])\n",
    "print ('Prediction Caption:', ' '.join(result))\n",
    "#plot_attention(img_test[0], result, attention_plot)\n",
    "# opening the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Caption: 3 z m p u 2 m k\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(img_test[9])\n",
    "print ('Prediction Caption:', ' '.join(result))\n",
    "#plot_attention(img_test[9], result, attention_plot)\n",
    "# opening the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Caption: 5 a p 0 s 9 g f\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(img_test[5])\n",
    "print ('Prediction Caption:', ' '.join(result))\n",
    "#plot_attention(img_test[5], result, attention_plot)\n",
    "# opening the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_results(images, labels, num_imgs=10):\n",
    "    for i in range(0, num_imgs):\n",
    "        result = evaluate(images[i])\n",
    "        print('Prediction Caption:', ' '.join(result))\n",
    "        print(f'Actual Caption: ', labels[i])\n",
    "        #plot_attention(images[i], result, attention_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Caption: 0 t v 0 a n \n",
      "\n",
      "Actual Caption:  \t3y+4=2\n",
      "\n",
      "Prediction Caption: 3 p v 9 \t r g 8\n",
      "Actual Caption:  \t8w+9=3\n",
      "\n",
      "Prediction Caption: b 9 c s n c q r\n",
      "Actual Caption:  \t6r+1=9\n",
      "\n",
      "Prediction Caption: b \n",
      "\n",
      "Actual Caption:  \t8r+6=4\n",
      "\n",
      "Prediction Caption: v q h j a n 0 =\n",
      "Actual Caption:  \t6z+0=5\n",
      "\n",
      "Prediction Caption: f k z p 3 3 n i\n",
      "Actual Caption:  \t1x+9=8\n",
      "\n",
      "Prediction Caption: o 3 8 5 u s h +\n",
      "Actual Caption:  \t0k+9=5\n",
      "\n",
      "Prediction Caption: 5 b l v v y j u\n",
      "Actual Caption:  \t5p+1=9\n",
      "\n",
      "Prediction Caption: 6 0 9 = k x m k\n",
      "Actual Caption:  \t2x+7=1\n",
      "\n",
      "Prediction Caption: 7 d e + \n",
      "\n",
      "Actual Caption:  \t1l+3=6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_results(img_test, img_test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Morgan Copy Image Captioning with Attention (Drive).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
