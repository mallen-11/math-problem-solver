{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import image\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "#use try, except for loss function to see if it will run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, logits_time_major=False, blank_index=-1, \n",
    "                 reduction=tf.keras.losses.Reduction.AUTO, name='ctc_loss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "        self.logits_time_major = logits_time_major\n",
    "        self.blank_index = blank_index\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        logit_length = tf.fill([tf.shape(y_pred)[0]], tf.shape(y_pred)[1])\n",
    "        print(f'y_true = {y_true}')\n",
    "        print(f'y_pred = {y_pred}')\n",
    "        print(f'logit_length = {logit_length}')\n",
    "        print(f'logits_time_major = {self.logits_time_major}')\n",
    "        print(f'blank_index = {self.blank_index}')\n",
    "        loss = tf.nn.ctc_loss(\n",
    "                labels=y_true,\n",
    "                logits=y_pred,\n",
    "                label_length=None,\n",
    "                logit_length=logit_length,\n",
    "                logits_time_major=self.logits_time_major,\n",
    "                blank_index=self.blank_index)\n",
    "        #except ValueError as e:\n",
    "        #    print(f'error:')\n",
    "        #    loss = 0\n",
    "            \n",
    "        print('made it here')\n",
    "        return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='sequence_accuracy', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.total = self.add_weight(name='total', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "                \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true_shape = tf.shape(y_true)\n",
    "        batch_size = y_true_shape[0]\n",
    "        y_pred_shape = tf.shape(y_pred)\n",
    "        max_width = tf.maximum(y_true_shape[1], y_pred_shape[1])\n",
    "        logit_length = tf.fill([batch_size], y_pred_shape[1])      \n",
    "        decoded, _ = tf.nn.ctc_greedy_decoder(\n",
    "            inputs=tf.transpose(y_pred, perm=[1, 0, 2]),\n",
    "            sequence_length=logit_length)\n",
    "        y_true = self.to_dense(y_true, [batch_size, max_width])\n",
    "        y_pred = self.to_dense(decoded[0], [batch_size, max_width])\n",
    "        num_errors = tf.math.reduce_any(\n",
    "            tf.math.not_equal(y_true, y_pred), axis=1)\n",
    "        num_errors = tf.cast(num_errors, tf.float32)\n",
    "        num_errors = tf.reduce_sum(num_errors)\n",
    "        batch_size = tf.cast(batch_size, tf.float32)\n",
    "        self.total.assign_add(batch_size)\n",
    "        self.count.assign_add(batch_size - num_errors)\n",
    "\n",
    "    def to_dense(self, tensor, shape):\n",
    "        tensor = tf.sparse.reset_shape(tensor, shape)\n",
    "        tensor = tf.sparse.to_dense(tensor, default_value=-1)\n",
    "        tensor = tf.cast(tensor, tf.float32)\n",
    "        return tensor\n",
    "\n",
    "    def result(self):\n",
    "        return self.count / self.total\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.count.assign(0)\n",
    "        self.total.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "try:\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "except AttributeError:\n",
    "    # tf < 2.4.0\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "class Dataset(tf.data.TextLineDataset):\n",
    "    def __init__(self, filename, **kwargs):\n",
    "        self.dirname = os.path.dirname(filename)\n",
    "        super().__init__(filename, **kwargs)\n",
    "\n",
    "    def parse_func(self, line):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def parse_line(self, line):\n",
    "        line = tf.strings.strip(line)\n",
    "        img_relative_path, label = self.parse_func(line)\n",
    "        img_path = tf.strings.join([self.dirname, os.sep, img_relative_path])\n",
    "        return img_path, label\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def parse_func(self, line):\n",
    "        splited_line = tf.strings.split(line)\n",
    "        img_relative_path, label = splited_line[0], splited_line[1]\n",
    "        return img_relative_path, label\n",
    "    \n",
    "class DatasetBuilder():\n",
    "\n",
    "    def __init__(self, table_path, img_shape=(32, None, 3), max_img_width=300, \n",
    "                 ignore_case=False):\n",
    "        # map unknown label to 0\n",
    "        self.table = tf.lookup.StaticHashTable(tf.lookup.TextFileInitializer(\n",
    "            table_path, tf.string, tf.lookup.TextFileIndex.WHOLE_LINE, \n",
    "            tf.int64, tf.lookup.TextFileIndex.LINE_NUMBER), 0)\n",
    "        self.img_shape = img_shape\n",
    "        self.ignore_case = ignore_case\n",
    "        if img_shape[1] is None:\n",
    "            self.max_img_width = max_img_width\n",
    "            self.preserve_aspect_ratio = True\n",
    "        else:\n",
    "            self.preserve_aspect_ratio = False\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self.table.size()\n",
    "\n",
    "    def _parse_annotation(self, path):\n",
    "        with open(path) as f:\n",
    "            line = f.readline().strip()\n",
    "        if re.fullmatch(r'.*/*\\d+_.+_(\\d+)\\.\\w+ \\1', line):\n",
    "            return MJSynthDataset(path)\n",
    "        elif re.fullmatch(r'.*/*word_\\d\\.\\w+, \".+\"', line):\n",
    "            return ICDARDataset(path)\n",
    "        elif re.fullmatch(r'.+\\.\\w+ .+', line):\n",
    "            return SimpleDataset(path)\n",
    "        else:\n",
    "            raise ValueError('Unsupported annotation format')\n",
    "\n",
    "    def _concatenate_ds(self, ann_paths):\n",
    "        datasets = [self._parse_annotation(path) for path in ann_paths]\n",
    "        concatenated_ds = datasets[0].map(datasets[0].parse_line)\n",
    "        for ds in datasets[1:]:\n",
    "            ds = ds.map(ds.parse_line)\n",
    "            concatenated_ds = concatenated_ds.concatenate(ds)\n",
    "        return concatenated_ds\n",
    "\n",
    "    def _decode_img(self, filename, label):\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.io.decode_jpeg(img, channels=self.img_shape[-1])\n",
    "        if self.preserve_aspect_ratio:\n",
    "            img_shape = tf.shape(img)\n",
    "            scale_factor = self.img_shape[0] / img_shape[0]\n",
    "            img_width = scale_factor * tf.cast(img_shape[1], tf.float64)\n",
    "            img_width = tf.cast(img_width, tf.int32)\n",
    "        else:\n",
    "            img_width = self.img_shape[1]\n",
    "        img = tf.image.resize(img, (self.img_shape[0], img_width))\n",
    "        return img, label\n",
    "\n",
    "    def _filter_img(self, img, label):\n",
    "        img_shape = tf.shape(img)\n",
    "        return img_shape[1] < self.max_img_width\n",
    "\n",
    "    def _tokenize(self, imgs, labels):\n",
    "        chars = tf.strings.unicode_split(labels, 'UTF-8')\n",
    "        tokens = tf.ragged.map_flat_values(self.table.lookup, chars)\n",
    "        # TODO(hym) Waiting for official support to use RaggedTensor in keras\n",
    "        tokens = tokens.to_sparse()\n",
    "        return imgs, tokens\n",
    "\n",
    "    def build(self, ann_paths, batch_size, is_training):\n",
    "        # TODO(hym) Whether need to add AUTOTUNE to map function.\n",
    "        ds = self._concatenate_ds(ann_paths)\n",
    "        if self.ignore_case:\n",
    "            ds = ds.map(lambda x, y: (x, tf.strings.lower(y)))\n",
    "        if is_training:\n",
    "            ds = ds.shuffle(buffer_size=10000)\n",
    "        ds = ds.map(self._decode_img)\n",
    "        if self.preserve_aspect_ratio and batch_size != 1:\n",
    "            ds = ds.filter(self._filter_img)\n",
    "            ds = ds.padded_batch(batch_size, drop_remainder=is_training)\n",
    "        else:\n",
    "            ds = ds.batch(batch_size, drop_remainder=is_training)\n",
    "        ds = ds.map(self._tokenize)\n",
    "        ds = ds.prefetch(AUTOTUNE)\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_builder = DatasetBuilder('table1.txt')\n",
    "train_ds = dataset_builder.build(['data.txt','data.txt'], 200, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "/linear_fcns/images/2443.png; No such file or directory\n\t [[{{node ReadFile}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2101\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2609\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2610\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2611\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /linear_fcns/images/2443.png; No such file or directory\n\t [[{{node ReadFile}}]] [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-00cbc78c0c43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /linear_fcns/images/2443.png; No such file or directory\n\t [[{{node ReadFile}}]]"
     ]
    }
   ],
   "source": [
    "list(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def load_images_from_folder(folder, n_imgs=-1):\n",
    "    images = []\n",
    "    image_nums = []\n",
    "    for filename in os.listdir(folder)[:n_imgs]:\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            image_nums.append(filename.strip('.png'))\n",
    "    return images, image_nums\n",
    "\n",
    "folder=\"../../../Math Equations/linear_fcns/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, fnames = load_images_from_folder(folder,18000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../../../Math Equations/linear_fcns/data.csv')\n",
    "labels['img_number'] = labels['filename'].apply(lambda x: x.split('/')[-1].strip('.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = labels[labels['img_number'].isin(fnames)]['latex'].values\n",
    "label_array = [f'\\t{la}\\n' for la in label_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "images = 255 - images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = tf.image.resize_with_pad(images, 72, 225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fab8b345cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train, img_test, img_train_name, img_test_name = train_test_split(images, label_array, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum length of any caption in our dataset\n",
    "def calc_max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the top 5000 words from the vocabulary\n",
    "top_k = 41\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n",
    "                                                  oov_token=\"<unk>\",\n",
    "                                                  filters=' ',\n",
    "                                                  char_level=True)\n",
    "tokenizer.fit_on_texts(img_train_name)#label_array)\n",
    "train_seqs = tokenizer.texts_to_sequences(img_train_name)\n",
    "\n",
    "# Padding\n",
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "\n",
    "# Create the tokenized vectors\n",
    "train_seqs = tokenizer.texts_to_sequences(img_train_name)\n",
    "test_seqs = tokenizer.texts_to_sequences(img_test_name)\n",
    "\n",
    "# Pad each vector to the max_length of the captions\n",
    "# If you do not provide a max_length value, pad_sequences calculates it automatically\n",
    "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')\n",
    "cap_vector_val = tf.keras.preprocessing.sequence.pad_sequences(test_seqs, padding='post')\n",
    "\n",
    "# Calculates the max_length, which is used to store the attention weights\n",
    "max_length = calc_max_length(train_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_words': 41,\n",
       " 'filters': ' ',\n",
       " 'lower': True,\n",
       " 'split': ' ',\n",
       " 'char_level': True,\n",
       " 'oov_token': '<unk>',\n",
       " 'document_count': 14400,\n",
       " 'word_counts': '{\"\\\\t\": 14400, \"4\": 4321, \"k\": 555, \"+\": 14400, \"3\": 4273, \"=\": 14400, \"1\": 4300, \"\\\\n\": 14400, \"6\": 4375, \"i\": 560, \"0\": 4306, \"8\": 4331, \"y\": 543, \"7\": 4351, \"9\": 4258, \"x\": 512, \"2\": 4329, \"q\": 538, \"5\": 4356, \"w\": 568, \"d\": 550, \"u\": 550, \"v\": 572, \"n\": 554, \"h\": 533, \"a\": 575, \"m\": 586, \"z\": 549, \"p\": 564, \"c\": 547, \"s\": 550, \"e\": 549, \"o\": 546, \"f\": 588, \"l\": 538, \"t\": 561, \"j\": 562, \"g\": 559, \"r\": 540, \"b\": 551}',\n",
       " 'word_docs': '{\"\\\\t\": 14400, \"4\": 4321, \"\\\\n\": 14400, \"1\": 4300, \"k\": 555, \"=\": 14400, \"+\": 14400, \"3\": 4273, \"0\": 4306, \"i\": 560, \"6\": 4375, \"8\": 4331, \"y\": 543, \"7\": 4351, \"x\": 512, \"9\": 4258, \"2\": 4329, \"q\": 538, \"5\": 4356, \"w\": 568, \"d\": 550, \"u\": 550, \"v\": 572, \"n\": 554, \"h\": 533, \"a\": 575, \"m\": 586, \"z\": 549, \"p\": 564, \"c\": 547, \"s\": 550, \"e\": 549, \"o\": 546, \"f\": 588, \"l\": 538, \"t\": 561, \"j\": 562, \"g\": 559, \"r\": 540, \"b\": 551}',\n",
       " 'index_docs': '{\"2\": 14400, \"11\": 4321, \"5\": 14400, \"13\": 4300, \"26\": 555, \"4\": 14400, \"3\": 14400, \"14\": 4273, \"12\": 4306, \"24\": 560, \"6\": 4375, \"9\": 4331, \"36\": 543, \"8\": 4351, \"41\": 512, \"15\": 4258, \"10\": 4329, \"38\": 538, \"7\": 4356, \"20\": 568, \"29\": 550, \"30\": 550, \"19\": 572, \"27\": 554, \"40\": 533, \"18\": 575, \"17\": 586, \"32\": 549, \"21\": 564, \"34\": 547, \"31\": 550, \"33\": 549, \"35\": 546, \"16\": 588, \"39\": 538, \"23\": 561, \"22\": 562, \"25\": 559, \"37\": 540, \"28\": 551}',\n",
       " 'index_word': '{\"1\": \"<unk>\", \"2\": \"\\\\t\", \"3\": \"+\", \"4\": \"=\", \"5\": \"\\\\n\", \"6\": \"6\", \"7\": \"5\", \"8\": \"7\", \"9\": \"8\", \"10\": \"2\", \"11\": \"4\", \"12\": \"0\", \"13\": \"1\", \"14\": \"3\", \"15\": \"9\", \"16\": \"f\", \"17\": \"m\", \"18\": \"a\", \"19\": \"v\", \"20\": \"w\", \"21\": \"p\", \"22\": \"j\", \"23\": \"t\", \"24\": \"i\", \"25\": \"g\", \"26\": \"k\", \"27\": \"n\", \"28\": \"b\", \"29\": \"d\", \"30\": \"u\", \"31\": \"s\", \"32\": \"z\", \"33\": \"e\", \"34\": \"c\", \"35\": \"o\", \"36\": \"y\", \"37\": \"r\", \"38\": \"q\", \"39\": \"l\", \"40\": \"h\", \"41\": \"x\", \"0\": \"<pad>\"}',\n",
       " 'word_index': '{\"<unk>\": 1, \"\\\\t\": 2, \"+\": 3, \"=\": 4, \"\\\\n\": 5, \"6\": 6, \"5\": 7, \"7\": 8, \"8\": 9, \"2\": 10, \"4\": 11, \"0\": 12, \"1\": 13, \"3\": 14, \"9\": 15, \"f\": 16, \"m\": 17, \"a\": 18, \"v\": 19, \"w\": 20, \"p\": 21, \"j\": 22, \"t\": 23, \"i\": 24, \"g\": 25, \"k\": 26, \"n\": 27, \"b\": 28, \"d\": 29, \"u\": 30, \"s\": 31, \"z\": 32, \"e\": 33, \"c\": 34, \"o\": 35, \"y\": 36, \"r\": 37, \"q\": 38, \"l\": 39, \"h\": 40, \"x\": 41, \"<pad>\": 0}'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Conv2D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2179fa268584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m72\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconv_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconv_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconv_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconv_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Conv2D' is not defined"
     ]
    }
   ],
   "source": [
    "conv_1 = Conv2D(64, kernel_size=(3, 3), strides=1,activation='linear',input_shape=(72,360,1),padding='same')\n",
    "conv_2 = Conv2D(128, kernel_size=(3, 3),strides=1,activation='linear',padding='same')\n",
    "conv_3 = Conv2D(256, kernel_size=(3, 3),strides=1,activation='linear',padding='same')\n",
    "conv_4 = Conv2D(256, kernel_size=(3, 3),strides=1,activation='linear',padding='same')\n",
    "conv_5 = Conv2D(512, kernel_size=(3, 3),strides=1,activation='linear',padding='same')\n",
    "conv_6 = Conv2D(512, kernel_size=(3, 3),strides=1,activation='linear',padding='same')\n",
    "conv_7 = Conv2D(512, kernel_size=(2, 2),strides=1,activation='linear',padding='same')\n",
    "\n",
    "max_p_1 = MaxPooling2D((2, 2), strides=2, padding='same')\n",
    "max_p_2 = MaxPooling2D((2, 2), strides=2, padding='same')\n",
    "max_p_3 = MaxPooling2D((1, 2), strides=2, padding='same')\n",
    "max_p_4 = MaxPooling2D((1, 2), strides=2, padding='same')\n",
    "\n",
    "batch_N = BatchNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential()\n",
    "model_cnn.add(conv_1)\n",
    "model_cnn.add(max_p_1)\n",
    "model_cnn.add(conv_2)\n",
    "model_cnn.add(max_p_2)\n",
    "model_cnn.add(conv_3)\n",
    "model_cnn.add(conv_4)\n",
    "model_cnn.add(max_p_3)\n",
    "model_cnn.add(conv_5)\n",
    "model_cnn.add(batch_N)\n",
    "model_cnn.add(conv_6)\n",
    "model_cnn.add(batch_N)\n",
    "model_cnn.add(max_p_4)\n",
    "model_cnn.add(conv_7)\n",
    "model_cnn.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_style(x):\n",
    "    \"\"\"\n",
    "    The original feature extraction structure from CRNN paper.\n",
    "    Related paper: https://ieeexplore.ieee.org/abstract/document/7801919\n",
    "    \"\"\"\n",
    "    x = layers.Conv2D(\n",
    "        64, 3, padding='same', activation='relu', name='conv1')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, padding='same', name='pool1')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        128, 3, padding='same', activation='relu', name='conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, padding='same', name='pool2')(x)\n",
    "\n",
    "    x = layers.Conv2D(256, 3, padding='same', use_bias=False, name='conv3')(x)\n",
    "    x = layers.BatchNormalization(name='bn3')(x)\n",
    "    x = layers.Activation('relu', name='relu3')(x)\n",
    "    x = layers.Conv2D(\n",
    "        256, 3, padding='same', activation='relu', name='conv4')(x)\n",
    "    x = layers.MaxPool2D(\n",
    "        pool_size=2, strides=(2, 1), padding='same', name='pool4')(x)\n",
    "\n",
    "    x = layers.Conv2D(512, 3, padding='same', use_bias=False, name='conv5')(x)\n",
    "    x = layers.BatchNormalization(name='bn5')(x)\n",
    "    x = layers.Activation('relu', name='relu5')(x)\n",
    "    x = layers.Conv2D(\n",
    "        512, 3, padding='same', activation='relu', name='conv6')(x)\n",
    "    x = layers.MaxPool2D(\n",
    "        pool_size=2, strides=(2, 1), padding='same', name='pool6')(x)\n",
    "\n",
    "    x = layers.Conv2D(512, 2, use_bias=False, name='conv7')(x)\n",
    "    x = layers.BatchNormalization(name='bn7')(x)\n",
    "    x = layers.Activation('relu', name='relu7')(x)\n",
    "\n",
    "    x = layers.Reshape((-1, 512), name='reshape7')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_model(num_classes, img_shape=(72, 360, 3)):\n",
    "    \"\"\" build CNN-RNN model \"\"\"\n",
    "\n",
    "    img_input = tf.keras.Input(shape=img_shape)\n",
    "    #x = tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(img_input)\n",
    "    \n",
    "    x = vgg_style(img_input)\n",
    "\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(units=256, return_sequences=True), name='bi_lstm1')(x)\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(units=256, return_sequences=True), name='bi_lstm2')(x)\n",
    "    logits = layers.Dense(units=num_classes, name='fc1')(x)\n",
    "    return tf.keras.Model(inputs=img_input, outputs=logits, name='CRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_classes = 41)\n",
    "\n",
    "model.compile(optimizer='adam', loss=CTCLoss(), metrics=[SequenceAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ds = tf.data.Dataset.from_tensors((img_train, img_train_name))\n",
    "val_ds = tf.data.Dataset.from_tensors((img_test, img_test_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 72, 360, 3) for input Tensor(\"input_4:0\", shape=(None, 72, 360, 3), dtype=float32), but it was called on an input with incompatible shape (200, 32, None, 3).\n",
      "y_true = SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"ctc_loss/Cast:0\", shape=(None,), dtype=int32), dense_shape=Tensor(\"DeserializeSparse:2\", shape=(2,), dtype=int64))\n",
      "y_pred = Tensor(\"CRNN/fc1/BiasAdd:0\", shape=(200, None, 41), dtype=float32)\n",
      "logit_length = Tensor(\"ctc_loss/Fill:0\", shape=(None,), dtype=int32)\n",
      "logits_time_major = False\n",
      "blank_index = -1\n",
      "made it here\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 72, 360, 3) for input Tensor(\"input_4:0\", shape=(None, 72, 360, 3), dtype=float32), but it was called on an input with incompatible shape (200, 32, None, 3).\n",
      "y_true = SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"ctc_loss/Cast:0\", shape=(None,), dtype=int32), dense_shape=Tensor(\"DeserializeSparse:2\", shape=(2,), dtype=int64))\n",
      "y_pred = Tensor(\"CRNN/fc1/BiasAdd:0\", shape=(200, None, 41), dtype=float32)\n",
      "logit_length = Tensor(\"ctc_loss/Fill:0\", shape=(None,), dtype=int32)\n",
      "logits_time_major = False\n",
      "blank_index = -1\n",
      "made it here\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": " /linear_fcns/images/8184.png; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_34109]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a3ea90deb893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m:  /linear_fcns/images/8184.png; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_34109]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=20,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = {'a': 1, 'b': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d5ad8062f0f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'c'"
     ]
    }
   ],
   "source": [
    "D['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14400, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t9w+4=8\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CRNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 72, 360, 3)]      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 72, 360, 64)       1792      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 36, 180, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 36, 180, 128)      73856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 18, 90, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 18, 90, 256)       294912    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 18, 90, 256)       1024      \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 18, 90, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 18, 90, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 9, 90, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 9, 90, 512)        1179648   \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (None, 9, 90, 512)        2048      \n",
      "_________________________________________________________________\n",
      "relu5 (Activation)           (None, 9, 90, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 9, 90, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "pool6 (MaxPooling2D)         (None, 5, 90, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv7 (Conv2D)               (None, 4, 89, 512)        1048576   \n",
      "_________________________________________________________________\n",
      "bn7 (BatchNormalization)     (None, 4, 89, 512)        2048      \n",
      "_________________________________________________________________\n",
      "relu7 (Activation)           (None, 4, 89, 512)        0         \n",
      "_________________________________________________________________\n",
      "reshape7 (Reshape)           (None, 356, 512)          0         \n",
      "_________________________________________________________________\n",
      "bi_lstm1 (Bidirectional)     (None, 356, 512)          1574912   \n",
      "_________________________________________________________________\n",
      "bi_lstm2 (Bidirectional)     (None, 356, 512)          1574912   \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 356, 41)           21033     \n",
      "=================================================================\n",
      "Total params: 8,724,649\n",
      "Trainable params: 8,722,089\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
